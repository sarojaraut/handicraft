Real time data integration

This configuration is used heavily in global companies that have distributed systems and need to keep local databases synchronized in real time.

For this purpose, Oracle GoldenGate provides a nonintrusive, fast-to-deploy method for moving data in real time, with minimal impact, using an architecture that is substantially easier to customize and maintain as application requirements change.

Data verification. Oracle GoldenGate Veridata

Data integration. New and changed data from its clinical information system application is immediately fed to the data warehouse to enhance reporting and business intelligence. enable a “single view of the customer” and improve reporting capabilities.

Zero-downtime operations.

The Oracle GoldenGate 12c architecture consists of decoupled modules that can be combined across the enterprise to provide maximum flexibility, availability, and performance. This architecture facilitates the movement of transactional data in four simple, yet powerful steps.

? Capture. Oracle GoldenGate captures changed data operations committed in the database transaction logs in a nonintrusive, high-performance, low-overhead implementation.

? Route. Oracle GoldenGate can use a variety of transport protocols, and it can compress and encrypt changed data prior to routing. Transactional data can be delivered via Open Database Connectivity?compliant databases or through a specialized adapter to a JMS message queue or topic.

? Transform. At any point prior to applying the data to the target system, Oracle GoldenGate can be used to execute a number of built-in functions, such as filtering and transformations.

? Apply. Oracle GoldenGate applies the changed transactional data to one or more database targets with only low latency, preserving transactional integrity.

Oracle GoldenGate consists of four distinct modules and components:
? Oracle GoldenGate Capture
? Oracle GoldenGate Trail Files
? Oracle GoldenGate Delivery
? Oracle GoldenGate Manager

Oracle GoldenGate Capture
The Capture module grabs committed transactions resulting from insert, update, and delete operations executed against a database, and routes them for distribution.
High-Speed, Low-Impact Data Capture
The Capture module does not require any changes to be made to the source database or the application it supports. To maintain optimal performance, the Capture module employs a range of CDC techniques against the source database. For instance, in databases that include transaction logs, changes are captured through direct access to native database transaction logs (redo logs, if applicable). 

Transaction logs contain all changes made to the database and are automatically maintained by the database application independently of Oracle GoldenGate. Consequently, no additional tables are required to run the Capture module, and overhead is greatly reduced as compared with trigger-based capture techniques. The Capture module can automatically adjust its transaction memory based on the size and number of the transactions it is capturing, which optimizes memory usage, allowing even lower overhead on the source systems.

Table, Row, and Column Selectivity
When not all changed data from the source needs to be replicated to the target system—such as for real-time reporting purposes—the Capture module allows users to filter tables and rows based on user-defined criteria and ignores the entries in the transaction log that don’t meet the end-user’s needs.

Efficient Network Use and Large Data Volumes
The Capture module can route transactions over WANs and LANs as well as the internet, and it can reduce network bandwidth requirements in a number of ways. Typically, the amount of data transmitted is only a fraction of the data that is generated by the database and stored in transaction logs. Because only committed transactions are propagated, intermediate activities and rolled-back operations are not transferred. Traffic is optimized by bundling individual records into larger, more-efficient packets and avoiding record-at-a-time bottlenecks. Several levels of data compression are available to further reduce the amount of network bandwidth required for transmission. For scenarios requiring very large changed data volumes, users can deploy multiple Capture modules to minimize the lag between source and target systems.

Checkpoints for Reliable Data Delivery
Oracle GoldenGate creates a checkpoint at the last changed transaction whenever a commit boundary is encountered. This enables the delivery of all committed records to the target, even in the event of a restart or cluster failover. Following a network or system outage, Oracle GoldenGate restarts from the last good checkpoint. 

Integrated Capture for Oracle Database
Beginning with Oracle GoldenGate 11g Release 2 Oracle Database users can take advantage of the Integrated Capture mechanism, which relies on Oracle’s internal log parsing and processing to capture DML transactions. By moving closer to the Oracle database engine, Oracle GoldenGate can take advantage of new Oracle Database features and functionality more quickly.
With Integrated Capture, Oracle GoldenGate now supports all flavors of compression used by Oracle Database and Oracle Exadata, including support for Exadata Hybrid Columnar Compression (EHCC), OLTP, and Segment compression. Integrated Capture also adds distributed transaction support for XA (distributed) and PDML (parallel DML) transactions on Oracle RAC. Finally, XML Object Relational and XML Binary data types are supported along with LOB full and partial reads (selective update) from the redo log. Integrated Capture is available for Oracle Database only and does not replace the existing Capture component on the other supported database platforms. Oracle GoldenGate licensing remains the same for Integrated Capture. For more information on this feature please review

Oracle GoldenGate Trail Files
Trail Files—Oracle GoldenGate’s unique queuing mechanism—contain the most recent changed data in a transportable, platform-independent format called the Oracle GoldenGate Universal Data Format, and can be converted to XML and other popular formats for consumption by different applications. The Capture module can create unique as well as overlapping sets of data in each Trail File. Based on the requirements of the implementation, users can store Trail Files on the target system, the source system, or both. Trail Files can be delivered to alternative queue types and application interfaces.

Flexible, Decoupled Architecture
A decoupled architecture addresses numerous problems inherent in tightly coupled alternatives. Process-to-process coupling creates a dependency between data capture and delivery. For example, if delivery is slower than capture, capture activities must be held up. In the event of an unplanned outage, decoupling ensures that the nonimpacted system continues to operate.

By staging data in Trail Files, Oracle GoldenGate decouples the data source and target for heterogeneous support. Unlike architectures that implement a tight process-to-process coupling, this decoupled architecture allows each module to perform its tasks independently.
Oracle GoldenGate also provides flexibility in the choice of hardware, operating system, and databases for sources and targets. For maximum flexibility and ease of use, customers can use different versions of Capture, Delivery, and Trail Files in the same implementation.

Data Pumps
Depending on the configuration and environment, it might be preferable to create Trail Files on the source system and use a separate Oracle GoldenGate feature, called a Data Pump, to continuously push—or “pump”—the Trail Files from the source system to the target system(s). This configuration enhances the fault tolerance and reliability of the overall Oracle GoldenGate environment. In the event of a network failure (between the source and the target systems), Oracle GoldenGate can continue to capture transactions because the data can be queued up locally in the Trail Files on the source, enhancing the recoverability in case of database failures.
The Data Pump feature is strongly recommended if data needs to be distributed to multiple targets from the same source (one to many). 

Archival and Audit Capabilities
Trail Files can create an archive of purged information from the source database by transforming delete and update records into inserts in a different location. For auditing and compliance purposes, Oracle GoldenGate can also maintain a separate history table to track each update to individual records as they change.

Oracle GoldenGate Delivery
The Delivery module takes any changed transactional data that has been placed in a Trail File and immediately applies it to the target database. Supported target databases include Oracle Database (including Oracle Exadata); Microsoft SQL Server; IBM DB2 (LUW), System z, System i; SybaseASE; those running on HP NonStop/Enscribe, SQL/MP, and SQL/MX, IBM Netezza, Greenplum, MySQL and TimesTen. Starting with Oracle GoldenGate 11g R2 Oracle GoldenGate can also deliver real-time data to PostgreSQL.

Data Integrity and Transaction Consistency
The Delivery module applies each database change in the same order as it was committed in the source database to provide data and referential integrity. In addition, it applies changes within the same transaction context as they were on the source system for consistency on the target.

Column Mapping and Transformation
As with Capture, users can configure the Delivery module via user-defined criteria to not only specify target tables but also individual rows and columns. By default, the Delivery module populates any target table column with data from a source table column if the two columns share the same name, and this is also true of like-named tables. However, you can easily configure Oracle GoldenGate to move data from a single table into multiple target tables or vice versa. This can be used to normalize or denormalize data in a data warehouse or OLTP environment. Users can also define explicit mapping and transformation rules, ranging from simple column assignments to more-complex transformations for which Oracle GoldenGate provides a suite of date, math, string, and utility functions. The module also supports the use of stored database procedures and functions and enables implicit mapping and explicit rules to be combined. If additional transformations, data quality, aggregation, and other functionality are required, Oracle GoldenGate 12c integrates with Oracle Data Integrator Enterprise Edition 12c to support end-to-end data integration.

Optimized High-Speed, High-Volume Data Delivery
The Delivery module provides a variety of techniques to optimize the posting of changed transactions to the target database. Oracle GoldenGate’s posting processes, where possible, run local to the target database, maximizing throughput by avoiding network limitations. The Delivery module also minimizes disk I/O while preserving original transaction properties. In addition, where possible, updates are executed via native database interfaces rather than through middleware, and internal caches are used to ensure fast execution of repetitive statements.
Multiple Delivery modules can be deployed to minimize lag time in the event of high data volumes during peak processing times or seasonality. This capture-route-transform-apply process runs continuously, so that the most recent transactions committed at the source are immediately moved and delivered to the target.

Deferred Apply
For maximum flexibility, the Delivery module can apply data immediately or at a deferred time chosen by the user, without losing transactional integrity. This allows an additional layer of data protection when needed and keeps the secondary system at a consistent state behind the primary system. In this configuration, Oracle GoldenGate routes the changed data to the Trail File on the target server but does not deliver it to the target database until all captured changes have been delivered to the target Trail File. All changed data in the target Trail File can then be immediately applied to the target database, to bring it to a consistent state relative to the source, whenever the user chooses.

Integrated Delivery
Customers delivering data to an Oracle Database 11g Release 11.2.0.4 or Oracle Database 12c Release 12.1.0.1 and higher database, can improve performance and provide better scalability and load balancing by using Integrated Delivery. Minimal changes are required to implement this change, which leverages the database parallel apply servers for automatic dependency aware parallel apply. With Integrated Delivery, there is no need for users to manually split the delivery process into multiple threads and manage multiple parameter files.

Coordinated Delivery
Customers delivering data to non-Oracle data stores (or Oracle Database versions before 11.2.0.4) who find it necessary to split their delivery process into multiple threads can use the Coordinated Delivery feature available with Oracle GoldenGate 12c to eliminate the need to manage multiple parameter files. In addition to requiring a single parameter file for multiple Delivery processes, Coordinated Delivery also automatically provides coordination across selected events that require ordering, including DDL, Primary Key updates, EMI and SQLEXEC.

Java Message Service Delivery
In addition to databases, Oracle GoldenGate can also publish changed data to JMS queues and topics by using Oracle GoldenGate Application Adapters.

Flat File Delivery
Using Oracle GoldenGate Application Adapters, Oracle GoldenGate can publish changed data in the form of flat files to integrate with third-party data management products such as ETL. For those ETL systems that perform faster reading files than scanning staging tables, this method minimizes storage resources and system maintenance.

Oracle GoldenGate Manager
To give users control over Oracle GoldenGate processes, the Manager module provides a command-line interface to perform a variety of administrative, housekeeping, and reporting activities, including
? Setting parameters to configure and fine-tune Oracle GoldenGate processes
? Starting, stopping, and monitoring the Capture and Delivery modules
? Critical, informational event, and threshold reporting
? Resource management
? Trail File management
The Manager module executes requests on demand as well as unattended. For example, it can be used to restart Oracle GoldenGate components as well as monitor latency. command-line interface to perform a variety of administrative, housekeeping, and reporting. The module also automatically recycles Trail File data when no longer needed, providing insurance against inadvertent disk-full conditions and offering an alternative to error-prone manual housekeeping procedures. Oracle GoldenGate 12c offers increased transaction tracing flexibility to easily identify bottlenecks and tune the Oracle GoldenGate implementation for optimum performance.

uniderectional - query offloading or zero downtime upgrade and migration
bidirectional - Hot standby or active active HA
Pear to pear - load balancing multi master
broadcast - data distribution
integration consolidation - datawarehouse
Datadistribution via messaging

Robust Data Security
Oracle GoldenGate 12c now supports Federal Information Protection Standard (FIPS) in addition to the default BLOWFISH encryption algorithms to provide secure data movement across systems and regions. FIPS compliant encryption can now be used for passwords, trail file data, and across the wire communications and includes using crypto algorithms and key management/storage.

Conflict Detection and Resolution
Conflict detection and resolution are key prerequisites of active-active or multimaster database configurations. When both systems are processing transactions and the activity is shared across multiple systems, detecting and addressing data conflicts becomes an essential requirement.
Oracle GoldenGate provides a wide variety of options for avoiding, detecting, and resolving conflicts. These options can be implemented globally, on an object-by-object basis, based on data values and filters, or through event-driven criteria including database error messages.

Oracle GoldenGate 12c offers conflict detection and resolution with a more complete framework that is more automated, and easier to implement than ever before. This is key when setting up conflict detection and resolution in complex environments using Active-Active and Multi-Master configurations. Conflict detection and resolution is used the same way in all supported environments.

Dynamic Rollback
Oracle GoldenGate provides a Dynamic Rollback feature that eliminates the need for full restore; helps maintain large test databases, and enables point-in-time and selective data recovery.

Eliminate the Need for Full Restore
Oracle GoldenGate can perform selective back-out (reverse) processing on enterprise databases, eliminating the need for full restore operations that, for large databases, usually require several hours or more to complete. The Dynamic Rollback feature captures and uses “before” and “after” images to undo database changes for user-defined tables, records, and time periods. This makes it ideal when data becomes corrupted or erroneously deleted.


Maintain Large Test Databases
Dynamic Rollback is also very effective for maintaining large test databases. Administrators can restore a test database to its original state before a test run, enabling test cycles to occur more quickly against a predictable baseline of data. Since Dynamic Rollback can undo all changes, reverting the database takes a fraction of the time compared to a full restore.

Point-in-Time and Selective Data Recovery
Using the Capture module to retrieve the database changes that have been committed, Dynamic Rollback can be applied to reverse operations to a specific point in time. The data is then analyzed and prepared for rollback by inverting the order of the database operations retrieved. This guarantees that records with the same key will be properly applied when done so in reverse order. The before and after image indicator in each record is modified, delete operations are changed to inserts, and inserts are changed to deletes. Then, the begin and end transaction indicators are reversed to delimit each transaction. The Delivery module is invoked to apply the before images back to the database. Before executing, users can review the changes to be applied.

User Exits
User exits are custom routines that can be called at different points during processing. With user exits, customers can respond to database events when they occur without altering production programs. For example, users can perform arithmetic operations, implement archival functions, gather statistics, or use exit routines as an alternative to native data transformation functions.

Stored Procedures and Queries
Stored procedures and queries can be called from Oracle GoldenGate to perform custom operations in the database’s native procedural language. They can execute a query and they can retrieve output parameters for input into Oracle GoldenGate’s filtering and mapping functions.

Macros
Macros offer a way to easily reuse parameters, commands, and conversion functions. They enhance productivity by enabling users to implement multiple uses of a statement, consolidate multiple commands, and invoke other macros.

Initial Data Loads
Oracle GoldenGate can be used for real-time CDC as well as for the initial loading to instantiate a database. Oracle GoldenGate’s initial load capabilities provide continuous uptime and allow the application to be introduced into the data environment quickly and effectively.
Oracle GoldenGate allows you to carry out an initial load across multiple systems nonintrusively and without downtime, in three steps.
? Start Capture. Places any changed data after its start in a Trail File. The Capture module acquires source data in arrays instead of rows for improved performance.
? Snapshot Load. Takes a snapshot from the source and loads it directly into the target.
? Start Delivery. Applies the data previously placed by in the Trail File to the target to “catch up” the database until both are fully synchronized. Oracle GoldenGate can be configured to automatically switch to CDC after the initial load is completed.

Oracle GoldenGate Veridata
Oracle GoldenGate Veridata is a high-speed, low-impact data comparison solution that identifies and reports data discrepancies between two databases, without interrupting those systems or the business processes they support. A standalone product, Oracle GoldenGate Veridata does not depend on the presence of Oracle GoldenGate’s core components.

Data discrepancies result from a wide variety of causes. User errors, application errors, and infrastructure problems can all lead to out-of-sync conditions. Inaccurate data leads to erroneous or ill-informed decision-making; failed service-level agreements; and, ultimately, financial and legal risk exposure. 
Oracle GoldenGate Veridata reduces the amount of time and resources required to compare data. Oracle GoldenGate Veridata offers an intuitive, Web-based graphical user interface as well as command-line capabilities to allow for scheduled comparisons.

Through an intuitive Web interface, users of Oracle GoldenGate Veridata can

? Operate against live databases to compare data sets at very high speeds, but with almost no impact on the infrastructure
? Compare only the data that changed since the initial comparison, enabling high performance
? Select pertinent tables or data fields on the source and target databases to compare—not an all-or-nothing approach
? Run multiple comparison jobs in parallel
? Compare heterogeneous databases, including Oracle, Teradata, Enscribe, and SQL/MP, on different operating systems

To initiate the comparison, users simply perform a few simple clicks in Oracle GoldenGate Veridata’s graphical interface or enter a command through its command-line interface. When Oracle GoldenGate Veridata starts, its agents on each datasource start to read the data from their respective databases. This allows the verification of data to be unattended.
Oracle GoldenGate Veridata agents use patent-pending technology to create row signatures that are not only very compact in size, but are also guaranteed to be unique. As the data on the source and target databases continue to change, Oracle GoldenGate Veridata server compares these row signatures and reports on persistent differences, as well as in-flight data that continue to change during the comparison. Users have the flexibility to determine how to handle in-flight data based on their own business requirements.

Oracle GoldenGate Conflict Detection and Resolution (CDR) provides basic conflict resolution routines that:
¦ Resolve a uniqueness conflict for an INSERT.
¦ Resolve a "no data found" conflict for an UPDATE when the row exists, but the before image of one or more columns is different from the current value in the database.
¦ Resolve a "no data found" conflict for an UPDATE when the row does not exist.
¦ Resolve a "no data found" conflict for a DELETE when the row exists, but the before
image of one or more columns is different from the current value in the database.
¦ Resolve a "no data found" conflict for a DELETE when the row does not exist.

Data types number, varchar, char, date, timestamp can be used with the COMPARECOLS parameter, the GETBEFORECOLS parameter, and as the resolution column in the USEMIN and USEMAX options of the RESOLVECONFLICT parameter. Only NUMERIC columns can be used for the USEDELTA option of RESOLVECONFLICT.

Configuring Oracle GoldenGate CDR
1. Making the Required Column Values Available to Extract 
The full before image of each record. For most supported databases, you can use the ADD TRANDATA command for this purpose.
Use the LOGALLSUPCOLS parameter to ensure that the full before and after images of the scheduling columns are written to the trail. Scheduling columns are primary key, unique index, and foreign key columns.
2. Configuring the Oracle GoldenGate Parameter Files for Conflict Resolution
1. Use the GETBEFORECOLS option of the Extract TABLE parameter to specify columns for which you want Extract to capture the before image of an update or delete operation. (For DB2 databases, use the GETUPDATEBEFORES)
2. Use the COMPARECOLS option of the MAP parameter in the Replicat parameter file to specify columns that are to be used with before values in the Replicat WHERE clause. The before values are compared with the current values in the target database to detect update and delete conflicts.
3. Use the RESOLVECONFLICT option of the MAP parameter to specify conflict resolution routines for different operations and conflict types. You can use RESOLVECONFLICT multiple times in a MAP statement to specify different resolutions for different conflict types.
You might need to create several routines that can be called in a logical order of priority so that the risk of failure is minimized.

Configuring the Oracle GoldenGate Parameter Files for Error Handling
CDR should be used in conjunction with error handling to capture errors that were resolved and errors that CDR could not resolve.

1. Conflict resolution is performed before these other error-handling parameters: HANDLECOLLSIONS, INSERTMISSINGUPDATES, and REPERROR. Use the REPERROR parameter to assign rules for handling errors that cannot be resolved by CDR, or for errors that you do not want to handle through CDR. It might be appropriate to have REPERROR handle some errors, and CDR handle others; however, if REPERROR and CDR are configured to handle the same conflict, CDR takes precedence.

2. (Optional) Create an exceptions table. When an exceptions table is used with an exceptions MAP statment, Replicat sends every operation that
generates a conflict (resolved or not) to the exceptions MAP statement to be mapped to the exceptions table. Omit a primary key on this table if Replicat is to process UPDATE and DELETE conflicts; otherwise there can be integrity constraint errors. At minimum, an exceptions table should contain the same columns as the target table. These rows will contain each row image that Replicat applied to the target (or tried to apply).

3. Create an exceptions MAP statement to map the exceptions data to the exceptions table. An exceptions MAP statement contains:
¦ (Required) The INSERTALLRECORDS option. This parameter converts all mapped operations to INSERTs so that all column values are mapped to the exceptions table.
¦ (Required) The EXCEPTIONSONLY option. This parameter causes Replicat to map operations that generate an error, but not those that were successful.
¦ (Optional) A COLMAP clause. If the names and definitions of the columns in the exceptions table are identical to those of the source table, and the exceptions table only contains those columns, no COLMAP is needed. However, if any names or definitions differ, or if there are extra columns in the exceptions table that you want to populate with additional data, use a COLMAP clause to map all columns.

Tools for Mapping Extra Data to the Exceptions Table
If the names and definitions of the source columns are identical to those of the target columns in the exceptions table, you can use the USEDEFAULTS keyword instead of explicitly mapping names. Otherwise, you must map those columns in the COLMAP clause, for example: COLMAP (exceptions_col1 = col1, [...])

To map the before image of the source row to columns in the exceptions table, use the @BEFORE conversion function
COLMAP (USEDEFAULTS, exceptions_col1 = @BEFORE (source_col1), &
exceptions_col2 = @BEFORE (source_col2), [...])

To map the current image of the target row to columns in the exceptions table, use a SQLEXEC query to capture the image, and then map the results of the query to the columns in the exceptions table by using the 'queryID.column' syntax in the COLMAP clause, as in the following example:

COLMAP (USEDEFAULTS, name_current = queryID.name, phone_current =
queryID.phone, [...])

To map timestamps, database errors, and other environmental information, use the appropriate Oracle GoldenGate column-conversion functions. For example, the following maps the current timestamp at time of execution.
res_date = @DATENOW ()

STATS REPLICAT group, REPORTCDR

MAP fin.src, TARGET fin.tgt,
COMPARECOLS (ON UPDATE ALL, ON DELETE ALL),
RESOLVECONFLICT (UPDATEROWEXISTS, (DEFAULT, USEMAX (last_mod_time)),
RESOLVECONFLICT (INSERTROWEXISTS, (DEFAULT, USEMAX (last_mod_time)),
RESOLVECONFLICT (DELETEROWEXISTS, (DEFAULT, OVERWRITE)),
RESOLVECONFLICT (UPDATEROWMISSING, (DEFAULT, OVERWRITE)),
RESOLVECONFLICT (DELETEROWMISSING, (DEFAULT, DISCARD)),
);


