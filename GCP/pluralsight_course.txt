https://app.pluralsight.com/library/courses/essential-google-cloud-infrastructure-foundation-1/transcript

Introduction
Course Introduction

[Autogenerated] Mhm Hello, I'm Phillip Meyer and I'm Elaine middle. We're both course developers at google cloud and we want to welcome you to Architect in with compute engine a series of three courses before we start using all of the different services that google cloud platform or g c p offers. Let's talk about what GDP is. When you look at google cloud, you'll see that it's actually part of a much larger ecosystem. This ecosystem consists of open source software providers, partners, developers, third party software and other cloud providers. Google is actually a very strong supporter of open source software. That's right now. Google cloud consists of chrome google devices, google maps, Gmail, google analytics, G suite, google search and the google cloud platform. G C P itself is a computing solution platform that really encompasses three core features, infrastructure, platform and software. This map represents gPS global infrastructure as of this recording GPS well provisioned global network connects over 60 zones to over 130 points of presence through a global network of fiber optic cables. And google is continuously investing in this network with new regions, points of presence and sub sea cable investments on top of this infrastructure, G C P uses state of the art. Software, defined networking and distributed systems technologies to host and deliver your services around the world. These technologies are represented by a suite of cloud based products and services that is continuously expanding. Many of the products and services are represented by unique blue hexagonal logos, such as the ones shown here. Now it's important to understand that there is usually more than one solution for a task or application in G C P. To better understand this, let's look at a solution continuum Google called platform spans from infrastructure as a service or I A s to software as a service says you really can build applications on G C p for the web or mobile that are global auto scaling and assistive and that provides services where the infrastructure is completely invisible to the user. It is not just that google has opened the infrastructure that powers applications like search, gmail, google maps and G suite. Google has opened all of these services that make these products possible and package them for your use. Alternative solutions are possible, for example, you could start up your own VM and google compute engine, install open source my SQL on it and run it just like a my SQL database on your own computer in a data center. Or you could use the cloud SQL service which provides a my SQL instance and handles operational work like backups and security, patching for you. Using the same services googled us to automate backups and patches. You could even move to a no SQL database that is auto scaling and serverless. So that growth no longer requires adding server instances or possibly changing the design to handle the new capacity. This series of courses focuses on the infrastructure. An I. T. Infrastructure is like a city infrastructure. The infrastructure is the basic underlying framework of fundamental facilities and systems such as transport, communications, power, water, fuel and other essential services. The people in the city are like users and the cars and bikes and buildings in the city are like applications. Everything that goes into creating and supporting those applications for the users is the infrastructure. The purpose of this course is to explore as efficiently and clearly as possible the infrastructure services provided by G C p. You should become familiar enough with the infrastructure services that you will know what services do and how to use them. We won't go into very deep die of case studies on specific vertical applications, but you'll know enough to put all the building blocks together to build your own solution. Now, g c p offers a range of compute service is the service that might be most familiar to newcomers, is compute engine which lets you run virtual machines on demand in the cloud. It's google Cloud's infrastructure as a service solution, it provides maximum flexibility for people who prefer to manage server instances themselves. Google kubernetes engine lets you run containerized applications on a cloud environment that google manages for you under your administrative control. Think of continue ization as a way to package code that's designed to be highly portable and to use resources very efficiently. And think of kubernetes as a way to orchestrate code in containers. app engine is GPS fully managed platform as a service framework. That means it's a way to run code in the cloud without having to worry about infrastructure. You just focus on your code and let google deal with all the provisioning and resource management. You can learn a lot more about app engine in the developing applications with google cloud platform course series. Cloud functions is a completely serverless execution environment or functions as a service. It executes your code in response to events. Whether those events occur once a day or many times per second. To google scales resources as required, but you only pay for the service while your coat runs the developing applications with google. Cloud platform core series also discusses cloud functions in this series of courses, compute engine will be our main focus. The architect In with google compute engine, courses are part of the cloud infrastructure learning path. This path is designed for I T. Professionals who are responsible for implementing deploying, migrating and maintaining applications in the cloud. The prerequisite for these courses is the google cloud platform fundamentals core infrastructure course, which you can find in the link section for this video. The Architect in with google compute engine series consists of three courses. Essential Cloud infrastructure Foundation is the first course of the Architect NG with compute engine series. In that course we start by introducing you to G C P and how to interact with the G C P console and cloud shell. Next we'll get into virtual networks and you will create BPc networks and other networking objects. Then we'll take a deep dive into virtual machines and you will create virtual machines using compute engine essentially cloud infrastructure core services. Z second course of this series. And that course we start by talking about cloud, I am and you will administer identity and access management for resources Next we'll cover the different data storage services in TCP and you will implement some of those services. Then we'll go over resource management where you will manage and examine building of GDP resources Lastly we'll talk about resource monitoring and you will monitor G C p. resources using stack drivers. services elastic cloud infrastructure scaling in automation is the last course of the series. In that course we start by going over the different options to interconnect networks to enable you to connect your infrastructure to G C P. Next we'll go over G Cps load balancing and auto scaling services which you will get to explore directly. Then we'll cover infrastructure, automation services like deployment manager and ______ form so that you can automate the development of DCP infrastructure services. Lastly we'll talk about other managed services that you might want to leverage in G C p. Now. Our goal for you is to remember and understand the different TCP services and features and also be able to apply your knowledge, analyze requirements, evaluate different options and create your own services And that's why these courses include interactive hands on labs through the Quick Labs platform. Quick Labs provisions you with a google account and credentials so you can access the G C p console for each lab at no cost.
Welcome to Essential Cloud Infrastructure: Foundation

Introduction to Google Cloud
Module Overview

[Autogenerated] In this module, we will provide you with an introduction to GDP by building on what you learned about the G. C. P infrastructure. From the course Introduction, this module is focused on how to interact with DCP. In the lab of this module, you will explore both the G CPS graphical user interface and its command line interface. You will also deploy a solution from the G C p marketplace without having to manually configure the software, virtual machine instances, storage or network settings to completely learning experience. I will provide a quick demo of projects. Let's get started.
Using Google Cloud

[Autogenerated] There are four ways you can interact with DCP and we'll talk about each in turn, there's the google Cloud platform console or G C p. console Cloud Shell and the Cloud SDK the Apis and the cloud mobile app. The GCB console provides a web based graphical user interface that you access through console dot cloud dot google dot com. For example, you can view your virtual machines and their details as shown on the top if you prefer to work in a terminal window. The Cloud SDK provides the G cloud command line tool, for example, you can list your virtual machines and their details as shown on the bottom with the G cloud compute instances. List Command. G C P also provides Cloud Shell, which is a browser based interactive shell environment for G C p. That you can access from the G C p. console Cloud Shell is a temporary virtual machine with five gigabytes of persistent disk storage that has the Cloud SDK preinstalled throughout this course, you will apply what you learn in different labs. These labs will have instructions to use the G c p consoles such as on the navigation menu, click compute engine VM instances. Let me dissect these instructions first. Within the Gcc console you will click on the icon with a three horizontal lines, which is the navigation menu as shown on the left. This opens a menu as shown on the right. All of the major products and services are listed on this menu. Then within the menu, hover over compute engine to open a sub menu. Finally click on VM instances on the sub menu, you will get more comfortable with these instructions and the G c p console as you work on labs. Now, labs will also use command line instructions. You will enter these instructions either in CloudTrail or an ssh terminal by simply copying and pasting them. In some cases, you will have to modify these commands, for example, when choosing a globally unique name for a cloud storage bucket. In addition to the cloud sDK, you can also use client libraries that enable you to easily create and manage resources GDP client libraries exposed apis for two main purposes. app APIs provide access to services and they are optimized for supported languages such as no. Js or python. Admin APIs offer functionality for resource management. For example, you can use admin APIs if you want to build your own automated tools. The cloud mobile app is another way to interact with DCP. It allows you to manage G c p services from your android or IOS device. For example, you can start stop and SSH into compute engine instances and see logs from each instance. You can also set up customizable grass, showing key metrics such as CPU usage, network usage request for seconds and server errors. The app even offers alerts and incident management and allows you to get up to date building information for your projects and get building alerts for projects that are going over budget. You can download the cloud mobile app from google play or from the app store.
Lab Intro: Console and Cloud Shell

[Autogenerated] slides are great for explaining concepts, but let's apply what we just talked about. In this first lab, you will explore the G. C peer interface that is the entry point of the graphical user interface that's called the G C p console Within the GCB console you will create a storage market and cloud storage, which is google's unified object storage. Then you repeat the same task using Cloud Shell, which is the command line interface in G C p. I encourage you to develop similarity with both the G C p Council and cultural and to become comfortable moving back and forth between them.
Getting Started With GCP And Qwiklabs

[Autogenerated] Hello and welcome. I'm Phillip Meyer, a course development with google cloud platform and this is a brief tutorial on using quick laps. In this course you're about to use the interactive hands on labs platform called Quick laps, which is part of google cloud. Quick Labs allows you to get practical hands on experience with BCP and provisions you with google account credentials so you can access the G c p counsel at no cost. Once you reach the lab item in this course, click the open button, you will then be prompted to provide the email that you want to use for your quick laps account. If you already have a quick let's account, you can use that email and then log in with your quick laps password if you don't have a quick tips account and new one will be created for you with the email that you provide. Once you're in quick Labs, click the start lap button and wait until lab running is displayed for each lab. You will have a timer with the remaining access time, you can see that right up here and your lab will automatically end when the time runs out to get started. You want to click the open google console button and you're going to want to sign in with the username and password that are provided in this pain over here. So let me copy the username click open google console I'm gonna paste in that username I'm going to go back and grab the password. You paste it in as well and quick let's create a new account. Few each time you launch a lab. Therefore you're gonna have to click through some initial account set up Windows. So in this case I'm going to accept this over here, I don't need to do anything here. I can just click done and then once I'm in the GCB console, I can verify that I'm using the quick tips provided account and project. I first need to also agree to the terms of service, click, agree and continue. And then over here within the dashboard I can see the project name, the project ID, the project number, I can also see the project idea up here and I want to make sure that these are the same and that they match D connection details that we have in the quick laps page. So let me go and verify that this here corresponds to the project idea over here and we can see it's just a cut off slightly. There there we go. Um so indeed we are using the right project and we can also verify that we're using the right user name and click on this icon up here. We can see we are not logged in with our own account but with the quick laps provided account and this is very crucial. So let's also verify that this corresponds to the user name that were provided over here. Okay, now some labs track you work within the quick clips provided gc project and if this is enabled you'll see a score in the top right corner of the quick glass window as you can see right here and you score increases as each of these objectives here are met and you can click on a score to the to view as you can see here the individual steps. So let me go ahead and complete these activities to show you what that looks like. Now that I have completed the lab, I can see that my score has been updated and I'm ready to click and lab and once I click and lab and confirm so the quick list provided project and any resources within that project will be deleted and I can continue learning and Pluralsight That's it for this tutorial. Remember to use the quick laps provided credentials to sign into the g C. P. console Good luck with the labs and enjoy the rest of this course.
Lab: Working with GCP Cloud Console and Cloud Shell

Lab Review: Console and Cloud Shell

[Autogenerated] in this lap, you created a cloud storage bucket using both the G C p console and cloud shell within G C P. The G C p console can do things CloudTrail can't and vice versa. For example, the G C p console can keep track of the context of your configuration activities, you can use the cloud API to determine from the current system state what options are valid and it can perform repetitive and more leveraged activities on your behalf. Cloud Shell in contrast offers detailed and precise control and through its commands away to script and automate activities. However, don't think of the consulate CloudTrail as alternatives. Think of it as one extremely flexible and powerful interface, you can stick around for a lab walkthrough but remember that G Cps user interface can change so your environment might look slightly different. Alright, so here we are in the G C P console and the first thing we're going to do is create a bucket using the Gcc console So to do that, I'm going to use the navigation menu which is the icon up here in the top left corner and I'm going to scroll down to storage which is here and click on browser and what we want to do is create a bucket. So I'm going to click the create bucket and the first thing we need to do is the fine and name and now this name needs to be a globally unique name. So you could for example, use your Quick Labs project IDE here. So that's what I'll do. Mhm and copy that, paste it in there. Um the instructions just say to create, you could also choose to change. The default storage class is currently set to multi regional. We'll talk more about that in a later module, you can control the access to the objects and there are even some advanced settings around encryption. So I'm just going to go ahead and click create and you can see that this now has created a bucket and here we see the bucket, IDE or the name. So now we're going to access cloud shell and then we're going to do this, we're gonna click this button up here in the right corner, just activate CloudTrail and then I'll prompt you to start CloudTrail so we'll click that as well and you can see that's coming up here, you can actually expand this and open this in a new tab or you could, you know, realigned is to get a little bit more real estate in here. And so we created a bucket using the GCB console. Now we're going to repeat the same using CloudTrail So I'm gonna go ahead and copy the command from the lab instructions and paste it in here. Now the command has the bucket name here in brackets and we want to change that. So this again has to be a globally unique name. And so what we could do is we could again grab the ID of our project and maybe just add something to it. We could just add dash shell to say that this is the one that we created from CloudTrail So the command is juice you till this is these are the commands for cloud storage and M B is the make bucket command, you see that it has created that here and we can see if we navigate in the GCB console back two buckets that we now have two buckets in here, so we're able to create both of those. So there are other collateral features that we can explore here. So while we're in CloudTrail we can click these three dots over here and get some more options. One of which is we can upload a file and if I click that, I'm just presented with my browser and I could for example select this text file and click open and we see that's being uploaded and now that has finished and then I can use the Ls command to list that file. So here is that file, there's also a README already in there and then we could copy that now that file to the bucket that we have. And so there's a command for that also in the lab instructions. So again we're working with cloud stores, so G sutil is going to be the command and cp to copy, We're going to give the name of the file so my file dot txt and then we want to get to that cloud storage bucket. And so we could choose either of the two buckets we've created. Why don't we choose the when we created from cloud shell, paste it in there. And then it's telling us that it's copying over the files and if we now go into that, we can see that now that file is in there, the file doesn't contain anything. So that's why it is that size. And then we could also go ahead and close cloud shell and do some other activities. Um tusk five of the lab goes into creating a persistent state in called shell. Um So you could open cloud shell and we could list, for example, all the available regions with the G cloud command that's listed in there. G Cloud compute regions list and from these regions we can now select a region and store that in an environment variable. So let's take the command from the lab instructions in for class region equals. And let's say for example I picked the U. S. Central one region. Could piece that in there stored and then I could verify that with the echo command just running that and it's not telling me that that is stored in there. The other thing we could do is we could expand this a little bit but we could also create a folder in here with the MK direct command and now we could create a configuration file and then we can append the environment variable that we just created to that file and then we could add another one. For example we could also store our project ID so I can put that in there, grab my project ID copy that and store that in the environment variable. And then I run the command from the lab instructions to also depend the value of the project I did to my a mind of verbal in the configuration file and then I can just verify all of that and make sure that that's been stored. So this gives us a method to create environment variables and easily recreate them. If collateral is cycled however, you will still need to remember to issue the source command each time CloudTrail has opened. So let's modify the dot profile file so that the source command is issued automatically Any time a terminal CloudTrail is opened so we're going to close and reopen CloudTrail So let me do that. Close it and then reopen it and then I'm going to paste the echo command again. We see that it's not out putting anything so that commanders criminal not down. So let's modify that dot profile file using nano. And at the end of that file let's go all the way to the bottom, we're going to paste in sourcing for class conflict and then we're going to save that file to profile and then exit and then let's verify that we are able to get that environment variable um that is project IDE so that's currently not in there. That is because I haven't restarted it, profile gets run when I restart. Sorry for that. So let me close it, let me reopen it. Mhm and then let's verify and there we go. Okay, so now we can see the expected value and that's because we edit the D dot profile file and that's it. So we've leveraged in this lab, the G c p console we created a storage bucket, We also created a storage bucket using cloud shell and then we looked into some features around kochel in terms of uploading files and copying those files to the storage bucket and um even at the end, configuring the profile and setting some environment variables. That's the end of the lab
Lab Intro: Infrastructure Preview

[Autogenerated] In this lab, you're going to experience the power of DCP automation by setting up a complete Jenkins continuous integration environment. Using the g C. P marketplace, you will then verify that you can manage the service from the Jenkins UI and administer the service from the VM host through SSH Now, you could accomplish a very similar result through manual configuration in a couple of hours or even days, but in this lab you'll see it set up in only a few minutes.
Lab: Infrastructure Preview

Lab Review: Infrastructure Preview

[Autogenerated] in this lab, you are able to launch a complete continuous integration solution in a few minutes, you demonstrated that you had user access through the Jenkins UI and that you had administrative access control over Jenkins by using Ssh to connect to the VM where the services hosted and by stopping and then restarting the services Many of the activities that occurred in that lab were nearly transparent and they use resources and methods that you learn about and the rest of this course examples of this include the acquisition and configuration of a network at p address, the provisioning of a virtual machine instance along with the installation of software on that machine and the passing of default state information from the environment. During the setup process, you can stick around for a lap walkthrough. But remember that G Cps user interface can change so your environment might look slightly different. So here I am in the G C. P council and the first thing I want to do is navigate to the marketplace. So up here, I've already clicked on the navigation menu and marketplace is pretty much on top. I'm going to click on that And now I want to search for Jenkins specifically the one that's certified by Vietnam me. So I can just directly paste that in these search address here and here we go. This is the one I'm looking for. So I'm going to click on that now. I can read all about this. There's an overview, It tells me this friend from compute engine uses a single virtual machine when it was last updated. It talks about all the packages, the operating system. If I scroll down, I can learn more about the pricing. There's obviously pricing associated with the VM instance itself. Um, it does not have a usage fee. If it did, that would be displayed here and you'll be built for all of that together. Um, there's a standard discharge and then there's a sustained use discount which will learn more about in a later module. So once I'm happy with all that and I've read through, I can go ahead and click on launch on compute engine. Yeah, now it's going to present me with an interface here where it could change the name, the zone machine, type, a lot of other settings that are very similar to configuring a virtual machine. I can again see all the software in terms of servers, the cost one more time and once I'm ready to go, I can click, accept the terms of services and click deploy. So now I'm actually in a different interface. This is a deployment manager. We learn about this later in the course series, but the interesting thing now is I can see the setup process. So there is an actual file here that has all the configuration in a ginger file. There is a VM that's being created. There are two firewall rules are created TCP for port 80 and 443 So that's http and https and I can wait for this machine to now come up. There's also some software configuration. I can again learn about all of the software that is installed here. I can click on the VM instance to get more information about it and we could see the VMS instances up the firewall rules are up. So the last thing that's happening here is the software is being configured and I can even learn more about that software here already clicked on that. So these are again all the different versions that we can get. And then again, once this is running these um this table up here will be populated all currently pending because this is still being initialized and there we can see that the instance is now ready. So there's a couple different things we could do. We have an admin user as well as a password so we can copy that, we could click on, visit the site and this is going to open that in a new tab that's just navigating us to the external iP address and it's gonna load. Um let's see, it's just starting. It's probably the service itself, it's still getting ready to work so you can see that the software in the background on the instance is installed but it also needs to launch um so that itself can take some time to and now it's up and running, I can put my user name in and I can put the password in and I can click sign in and once I'm in here I should be asked to customize Jenkins, there will be some suggested plug ins that I can install. Once I've done that I can restart the instance, um, deployment manager um, and the G three marketplace will also give you sometimes then suggested next steps. For example, this password up here, it's just temporary. So we could go change that. The other thing we could do is we could assign a static external I. P address so that when we visit the site, it's always going to be the same I. P address. That really helps if you have a DNS setup for this instance. If I go back here, I can click that, I want to install the suggested plug ins, it's going to do that. It's going to tell me where that instance is. Can save and finish and I can go start using it and they should again restart services so here we are, so I can explore this a little bit, I could manage Jenkins itself and there are lots of different actions that I could perform here and I could also no further administrative service. So if I go back to the console and I'm looking at this deployment here and looking at Jenkins one, I could actually SSH now to this instance, so let me click that button and that's going to establish now an ssh session to the service and I can then actually shut down all the services by copying the command that's in the lab instructions, so let me just paste that in here and run that. And if we go back to the Jenkins GUI and refresh that page, we'll see that it's gone right and that is expected because I have gone ahead and I have restarted that service so what I can do now is I can I stop them, I can now restart it by running the restart command in here. So let's grab that and paste that in here and now the service should come back up, we might have to refresh the page a couple of times for that to happen, so let's just wait a couple seconds, refresh it and see if that service comes back up. My tab name has changed to start in Jenkins, so it looks like that service is already coming back up right now and we can see that that service is getting ready right now. And so at this point we've completed all the tasks, I could now go back to the ssh session and exit out of here and here we see that Jenkins is back up and running and that's the end of the lab
Demo: Projects

[Autogenerated] Let's explore projects which are the key organizer of infrastructure resources and relate these resources to building accounts resources can only be created and consumed within projects in a way that projects isolate related resources from one another. I will demonstrate how to create and the lead projects and switch contacts between projects. Some of these actions cannot be performed in the quick laps environment due to security restrictions, therefore I'm going to demonstrate them in my environment. So here I am in the G c p console you can actually see there's a trial account and you can also create a trial account yourself. If you would like to follow along with this, essentially what I'm going to do first is go ahead and create a project. So I'm going to click up on my project name up here and there's this icon up here to create a new project. So let me go click that. And now the one thing I want to do is I want to define a project name. Um so let me just say my new project and you can see that automatically creates a project idea and that project idea is going to be unique versus my name is really not so unique. So let me click create on that and it is now telling me here that is going to create that project. I can follow along with that here in the notification pain. And one thing to notice is when you create a new project that some of the services that you're going to use may not be initially available. Um so here I now have my new project. I could now switch projects. So if I go to my home for example, I see here the project itself, I could go to the project settings. I could um shut that down or I could switch to a different one. So let me actually change up here to this new project that I created. You go in there and let's follow the process for shutting that down. So I'm going to click on shutdown. I want to make sure that I really want to do that. It's telling me a little bit about what's going to happen when I do this, specifically all building in traffic serving will stop, but the shutdown is actually scheduled so it will take 30 days and this is in case that you will not maybe undo this. So I need to just retyped my project idea can actually copy and paste that in here and I can click shutdown and it should not give me a notification. So here telling me when exactly it's going to shut this down and I can click ok on that. So now this is being scheduled for shutdown so now I can go back and obviously want to grabbing project. Um it's automatically putting me on the site. Alternatively, if I go home you'll see that. I also have an option up here. It's tell me, hey, you really need to select the project. So lots of different ways to go about. So I could click on that and select a project. Now I want to show in a second how we can also maybe switch projects um Spring cloud Shell. So let's actually go ahead and create another project. Let's just call this my second project. We can create that as well and they'll start in the background for us. So what I want to do now is I said I want to go to cloud shell so I go up here in the right corner. It's just activate cloud Shell. Just click on that. It doesn't ask me if you sure want to start CloudTrail because I've already been using Cloud child with this user. So it's also telling me that I haven't used my cloud show in a while so it has to an archive my disk and that's going to take a little bit of time. But once sets up, we can actually go use the key cloud conflict list command and we can paste that in. It's going to give us more information about the configuration that we currently have and that will include the project that we currently have selected and we can actually see the project right here. This is the project I'm working on right now. So if I paste in, uh I automatically copy that when I clicked on it. So I wanna instead typing here G Cloud Config list. So here we get some more information and I can also use the grew up commanding here to directly got my project and then we see this is the project that we're currently using. Okay, um I could actually now even change the focus of my GCB console to this new project and you'll see if I run this command again. My focus of cloud Shell is still focused on this other project that I had. So one thing we could do now is we could store the project, ID may be in an environment variable and then we could maybe set it so we could kind of swap back and forth. So let me get the project ideas right here and I'm going to maybe just store that in an environment variable and let's just call that my project I. D one. So let me grab the project, ID copy that, paste it in there. So now I have that stored and now I could use the G cloud conflict set project to define an action to change the project idea. And now you can see that I have that other project ID listed here, so I can actually see that. Um and I could also now use the same G cloud conflict list command and grab the project and you'll see that. Now I'm working with different project. That's how easy it is to create and delete projects and switch context between projects.
Module Review

[Autogenerated] In this module, we looked at how to use g c p, which you got to experience firsthand. In two short labs, I also gave a demonstration of how to use projects, which are the key organizer of infrastructure resources, now that you can interact with DCP, it's time to explore two of the foundational components of g c p. S infrastructure, virtual networks and virtual machines. So what are you waiting for? Move on to the next module to learn more?
Virtual Networks
Module Overview

[Autogenerated] in this module, we will be covering virtual networks. G C P uses a software defined network that is built on a global fiber infrastructure. This infrastructure makes G. C. P one of the world's largest and fastest networks. Thinking about resources as services instead of its hardware. Will help you understand the options that are available and their behavior. In this module, we start by introducing virtual private cloud or VPC, which is google's managed networking functionality for your cloud platform resources. Then we dissect networking into its fundamental components which are projects networks, sub networks, I. P. Addresses, routes and firewall rules along with network pricing. Next you will explore google cloud's network structure in a lab by creating networks of many different varieties and exploring the network relationships between them. After that, we will look at common network designs. This map represents google cloud on a high level google cloud consists of regions which are the icons and blue points of presence or pops which are the dots in blue. A global private network which is represented by the blue lines and services A region is a specific geographical location where you can run your resources. This map shows several regions that are currently operating as well as future regions. Regions indicated with blue icons have three zones. Iowa is an exception where the region called US Central One has four zones. Your central one a your central one be your central one, C and you are central one. F for up to date information on regions and zones. Please refer to the documentation in the slides the pops are where google's network is connected to the rest of the internet. Google cloud can bring its traffic closer to its peers because it operates an extensive global network of interconnection points. This reduces costs and provides users with a better experience. The network connects regions and Pops and is composed of a global network of fiber optic cables with several submarine cable investments. For more information about google's networking infrastructure, please refer to these slides, let's start by talking about GPS network and specifically virtual, private, cloud or VPC.
Virtual Private Cloud

[Autogenerated] with G CPU can provision your DCP resources connect them to each other and isolate them from each other in a virtual private cloud. You can also define fine great networking policies within GDP and between GDP and on premises or other public clouds. Essentially VPC is a comprehensive set of google managed networking objects which we will explore in detail throughout this module. Let me give you a high level overview of these objects. Projects are going to encompass every single service that you use including networks. Networks come in three different flavors, default auto mode and custom mode sudden networks allow you to divide or segregate your environment. Regions and zones for presents, google's data centers and they provide continuous data protection and high availability. BPC provides I. P addresses for internal and external use, along with granular I. P. Address range selections. As for virtual machines. In this module we will focus on configuring VM instances from a networking perspective will also go over roads and firewall rules
Projects, networks, and subnetworks

[Autogenerated] Let's start exploring the VPC objects by looking at projects. Networks and sub networks. Projects are the key organizer of infrastructure resources in G C P. A. Project associates objects and services with billing. Now it's unique. The projects actually contain entire networks. The default quota for each project is five networks, but you can simply request additional coda using the G c p console These networks can be shared with other projects or they can be peered with networks in other projects, both of which we'll cover later in the architect in with google compute engine core series. These networks do not have IP rangers but are simply a construct of all of the individual I. P addresses and services within that network GPS networks are global spending, all available regions across the world that I showed earlier. So you can have one network that little exists anywhere in the world. Asia, europe Americas all simultaneously. Inside a network. You can segregate your resources with regional sub networks. I just mentioned that there are different types of networks, default auto and custom. Let's explore these types of networks in more detail. Every project is provided with a default VPC network with preset subnets and firewall rules. Specifically a sub net is allocated for each region with non overlapping cider blocks and firewall rules that allow english traffic from iCMP, rdP and ssh traffic from anywhere as well as english traffic from within the default network. For all protocols and ports in an automotive network, one sub net from each region is automatically created within it. The default network is actually an autumn. A network. These automatically created subnets use a set of predefined ip ranges with a slash 20 mask that can be expanded to a slash 16. All of these subnets fit within the 10.1 28.0 dot zero slash nine cider block. Therefore, as new g c p regions become available, new subnets in those regions are automatically added to automotive networks using an IP range from that block, a customer network does not automatically create subnets. This type of network provides you with complete control over its subnets and IP rangers you decide which submits to create in regions you choose and using IP ranges you specify within the rfc 1918 address space. These IP ranges cannot overlap between subnets of the same network. Now you can convert an automotive network to a customer network to take advantage of the control that customer networks provide. However, this conversion is one way meaning that customer networks cannot be changed to automate networks. So carefully review the consideration for automotive networks to help you decide which type of network meets your needs. On this slide, we have an example of a project that contains five networks. All of these networks spend multiple regions across the world. As you can see on the right. Each network contains separate virtual machines A, B, C and D. Because VMS A and B are in the same network network one, they can communicate using their internal iP address even though they are in different regions, essentially your virtual machines, even if they exist in different locations across the world, take advantage of google's global fiber network. Those virtual machines appear as though they're sitting in the same wreck when it comes to a network configuration protocol. VMc MD, however, are not in the same network. Therefore by default, these VMS must communicate using their external I. P addresses even though they are in the same region. The traffic between VMc MD isn't actually touching the public internet, but it's going through the google edge routers. This has different building and security ramifications that we will explore later because VM instances within a VPc network can communicate privately on a global scale. A single VPN can securely connect your on premises network to a G C P network. As shown in this diagram, even though the two VM instances are in separate regions. Us West one and US East One, they leverage google's private network to communicate between each other and to an on premises network through a VPN gateway. This reduces costs and network management complexity. I mentioned that some networks work on a regional scale because the region contains several zones. Sub networks can cross zones. This light has a region, region one with two zones, owns A and B. Sub networks can extend across these zones within the same region, such as submit one. The subject is simply an I. P address range and you can use I. P addresses within that range. Notice that the 1st and 2nd address is in the range 0.0 and 0.1 are reserved for the network in these subnets gateway, respectively. This makes the 1st and 2nd available addresses 0.2 and three which are assigned to the VM instances. The other reserved addresses in every sub net are the second to last address in the range and the last address which is reserved as the broadcast address. So to summarize every sub net has four reserved I. P addresses in its primary IP range. Now, even though the two virtual machines in this example are in different zones, they still communicate with each other using the same submit I. P address. This means that a single firewall rule can be applied to both VMS, even though they are in different zones. Speaking of I. P addresses of a sub net google cloud VPc s let you increase the I. P address space of any subnets without any workload shutdown or downtime. This diagram illustrates a network with subnets that have different sub net masks, allowing for more instances in some subnets than others. This gives you flexibility and growth options to meet your needs, but there are some things to remember. The new sub net must not overlap with other subnets in the same VPc network in any region. Also, the new subnets must stay inside the rfc 1918 address spaces. The new network range must be larger than the original, which means the prefix length value must be a smaller number. In other words you cannot undo an expansion now auto mode subnets start with a slash 20 IP range. They can be expanded to a slash 16 IP range but no larger. Alternatively, you can convert the automotive sub network to a custom mode sub network to increase IP range further also avoid creating large subnets, overly large subnets are more likely to cause side arranged collisions when using multiple network interfaces and VPC network peering or when configuring a VPN or other connections to an on premises network. Therefore do not scale your sub net beyond what you actually need.
Demo: Expand a Subnet

[Autogenerated] Let me show you how to expand a custom submit within TCP. I've already created a custom submit with a slash 29 mask. A slash 29 mass provides you with eight addresses. But of those four are reserved by G C. P. Which leaves you with another four for your VM instances. Let's try to create another VM instance in this submit. So here we are on the G C. P. Console and I have my four instances and if I go into the network interface details here, you can see that these are part of a network and I have a sub net here and if I drill further into that, you can see that I currently have a slash 29. So let's go back and try to create that other instance. Just going to click on create instance. I don't need a very large machine Okay with a micro and let's hit create. And ideally we should be getting an era now about the fact that the IP space should have been exhausted. So we're just going to wait for that. You can also follow this along in the notification pain up here, can see that it is trying to create that right now and so we're going to wait for that and see if we get an error here in a second and once we have that we're going to go ahead and expand the subject. So here we can see that the instance creation has failed. I can hover over this and it's just telling me that the eyepiece base of that stuff that has been exhausted just like just as expected. And we actually have a retry button here as well as a notification pane, we're going to try to use that in a second. Once we expand the sub net to recreate that instance. Now what's important to note that all of these for instances are currently running, so we're not going to take any of these towns during the submit expansion. Now to expand the submit, I could go to VPC network through the navigation menu or I can go back by clicking on nick zero here, directly through the network interface details to the sub Net. This is what I want to change. So let me click the edit button and let's expand this all the way to a slash 23. And this is going to allow a lot of instances. Actually over 500 instances, we're gonna wait for this to update and then we're gonna head back and try to recreate that instance. So we can also follow this process along right here is still saving. So we're just going to hang on tight here. They should just take a couple of seconds I the receipts complete and now I still have that retry button here to recreate that instance. So let me actually click that and I can head back to compute engine to see if that is going to succeed. So here we are. And since five, it's being staged and will soon begin running. And let's see if this works out, we can see that already has now an internal I. P. Address allocated now that we've expanded the subject itself, and if I refresh this, we can see that the instance is now created. That's how easy it is to expand a submit in G c p without any workload shutdown or downtime.
IP addresses

[Autogenerated] now that we cover G C P networks at a high level, let's go deeper by exploring iP addresses, INGE keep each virtual machine can have two IP addresses assigned. One of them is an internal IP address which is going to be assigned via THP, internally every VM that starts up and any service that depends on virtual machines gets an internal iP address. Example of such services are app engine and kubernetes engine, which are explored in other courses. When you create a VM and G C P, it's symbolic name is registered with an internal DNS service that translates the name to the internal iP address. DNS is scoped to the network so it can translate web urals and VM names of hosts in the same network, but it can't translate host names from VMS in a different network. The other iP address is the external iP address, but this one is optional. You can assign an external iP address if your device or your machine is externally facing. That external iP address can be assigned from a pool, making it ephemeral. Or it can be assigned a reserved external IP address, making it static. If you reserve a static, external IP address and do not assign it to a resource, such as a VM instance or a forwarding rule, you are charged at a higher rate than for static and ephemeral external iP addresses that are in use.
Demo: Internal and external IP

[Autogenerated] I just mentioned that VMS can have internal and external I. P addresses. Let's explore this in the G. C. P. console So here I am on the compute engine page and what I'm going to do is just create a VM and walk through the process of choosing your internal and external I. P. Address. So let me click create. I can leave the name. You have obviously uh selection of regions and zones you can choose but I want to focus on the I. P. Addresses so let me go down to this option, expand management, security, this networking soul tenancy, let's focus on networking and he had the network interface, I'm going to click the pencil icon. I could choose between different networks so if I had different networks I could choose between them. That's not the case here. Um and then I have the primary internal IP and external IP So if we look at those options you can see that I can use an ephemeral address. Either the one that's created automatically. Um or I could custom select one. So within the range that I have here I could just type I. P. Address. I could also reserve a static internal iP address. This is great if you want to keep that I. P address for a longer time and we have similar options with the external API address but one of the big differences is that you can also just select none. Um So as I mentioned, your instances don't need to have an external I. P. Address. So let's just leave this as um ephemeral and by the way with the slash 20 here we have a lot of space in this IP range over 4000 addresses. Um So we could definitely have that many instances. They're also limits of how many instances you can have. Pen network as of this recording is actually 15,000. So do keep that in mind. You might have a very large range but it doesn't mean that you actually can create that many instances and that's a quota. Um There may also be actual limitations on physical hardware that's even available within a specific region or zone. So let me go ahead and create this instance and we're going to keep an eye on the internal and as well as the external I. P address once the instance is created and then we're also going to stop and start the instance to see if any of the IP address has changed. So here we can see the internal app address. So that is definitely within that space that we just looked at. Uh the external I. P address obviously is within google strange here and we could have reserved that but this is an FM Erawan. So let's actually test this out. I'm going to select the instance, I'm going to stop it. So it's telling me that if it doesn't compete with nine seconds it might be forced. So if you had any um shutdown scripts in here, you want to make sure that they can actually complete within 90 seconds. So let's run through that and remember this external I. P address that we currently have here as well as the internal I. P address. So this is going to take its time now. We can also click refresh to keep an eye on this. But this can this will take about 90 seconds and that's just to give your shutdown script enough time to perform any task to gracefully shut down this instance. So here we are. We can see the instances stop, the external API has gone. So now we're just going to start up that instance. Again, it's gonna tell us that we're gonna be built while it's running. That's fine. And you can see that the internal iP address remained the same while this instance stopped. So that has actually stayed for the time being. And now while this instance spins up, which we can, by the way, monitor the progress over here, um we should see that we should be getting a new external I. P. Address now because that was an ephemeral address. So here we can see the instance has started back up and we can see that the external iP address has changed. This demonstrates that every VM needs an internal IP address, but external I. P addresses are optional and by default there are ephemeral.
Mapping IP addresses

[Autogenerated] regardless of whether you use an ephemeral or static I. P address. The external address is unknown to the os of the VM. The external I. P addresses mapped to the VMS internal address transparently by vPc. I'm illustrating this here by running if conflict within a V M and G c P, which only returns the internal iP address. Let's explore this further by looking at DNS resolution for both internal and external addresses. Let's start with internal addresses. Each instance has a host name that can be resolved to an internal I. P address. This host name is the same as the instance name. There's also an internal fully qualified domain name or F Q D N for an instance that uses the format shown on the slide. If you delete and recreate an instance, the internal IP address can change this change can disrupt connections from other compute engine resources, which must obtain the new IP address before they can connect again. However, the DNS name always points to a specific instance no matter what the internal I P addresses. Each instance has a metadata server that also acts as a DNS resolver. For that instance, the metadata server handles all DNS queries for local network resources and writes all other queries to google's public DNS servers for public name resolution. I previously mentioned that an instance is not aware of any external I P address assigned to it. Instead, the network stores a look up table that matches external I P addresses with the internal I. P addresses of the relevant instances. For more information, including how to Serbia and resolve on instances. See the link section of this video. Now, let's look at external addresses, instances with external IP addresses can allow connections from hosts outside of the project. Users can do so directly using the external iP address. Public DNS records pointing to instances are not published automatically. However, admins can publish these using existing DNS servers. Domain and service can be hosted on G C p using cloud. DNS. This is a managed service that's definitely worth considering. So let's explore it in more detail. Cloud DNS is a scalable, reliable and managed, authoritative domain name system or DNS service running on the same infrastructure as google. Cloud DNS translate requests for domain names like google dot com into I. P addresses. Cloudiness uses google's global network of any cast name servers to serve your DNS zones from redundant locations around the world, providing lower latency and high availability for your users. High availability is very important because if you can't look up a domain name, the internet might as well be down. That's why G C P offers a 100% uptime service level agreement or LA for domains configured in cloudiness. For more information about this S L A. See the link section of this video. Cloud DNS lets you create and update millions of DNS records without the burden of managing your own DNS service and software. Instead, you use a simple user interface, command line interface or aPI for more information about cloudiness. See the link section of this video. Another networking feature of GDP is alias IP ranges. Alias IP ranges that you assign a range of internal addresses as an alias to original machines network interface. This is useful if you have multiple services running on a VM and you want to assign a different I. P address to each service. In essence, you can configure multiple I. P addresses representing containers or applications hosted in a VM without having to define a separate network interface, you just draw the LS IP range from the local subnets. Primary or secondary side arranges. This diagram provides a basic illustration of primary and secondary side arranges, and VM alias IP ranges. For more information about alias IP ranges, see the link section of this video.
IP addresses for default domains

Routes and firewall rules

[Autogenerated] so far you've learned about projects networks sub networks and I. P. Addresses. Let's use what you learn to understand how G. C. P. Routes traffic by default. Every network has routes that lead instances in a network send traffic directly to each other, even across subnets. In addition, every network has a default route that directs packets to destinations that are outside the network. Although these routes cover most of your normal routing needs, you can also create special routes that override these routes. Just creating a route does not ensure that your package will be received by the specified next top firewall rules must also allow the packet. The default network has pre configured firewall rules that allow all instances in the network to talk with each other manually created networks do not have such rules, so you must create them as you will experience. In the first lab routes match packets by destination I. P. Addresses. However, no traffic will flow without also matching a firewall rule, A route is created when a network is created, enabling traffic delivery from anywhere. Also, a route is created when a sub that is created. This is what enables VMS on the same network to communicate. This slide shows a simplified rotting table, but let's look at this in more detail. Each route in the routes collection may apply to one or more instances. A route applies to an instance if the network and instance tax match if the network matches and there are no instance tax specified. The route applies to all instances in that network compute engine then uses the routes collection to create individual read only routing tables for each instance. This diagram shows a massively scalable virtual router at the core of each network. Every virtual machine instance in the network is directly connected to this router and all packets leaving a virtual machine instance, our first handle at slayer before they are forwarded to the next top the original network router selects the next hop for a packet by consulting the routing table. For that instance, G C P firewall rules protect your virtual machine instances from unapproved connections, both inbound and outbound, known as ingress and egress, respectively. Essentially every VPC network functions as a distributed firewall. Although firewall rules are applied to the network as a whole connections are allowed or denied at the instance level. You can think of the Farrell as existing not only between your instances and other networks but between individual instances within the same network. G C P firewall rules are state fel This means that if a connection is allowed between a source and a target or a target and a destination, all subsequent traffic in either direction will be allowed. In other words, fire rules allow bidirectional communication once a session is established Also if for some reason all firewall rules in the network are deleted. There's still an implied deny all english rule and an implied allow all egos rule for the network. You can express your desired firewall configuration as a set of firewall rules. Conceptually a firewall rule is composed of the following parameters. The direction of the rule, inbound connections are matched against ingress rules only and up and connections are matched against eager schools only. The source of the connection for english packets or the destination of the connection for egress packets. The protocol and port of the connection where any rule can be restricted to apply to specific protocols only, or specific combinations of protocols and ports only. The action of the rule which is to allow or deny packets that match the direction, protocol, port and source or destination of the rule. The priority of the rule which governs the order in which rules are evaluated. The first matching rule is applied the rule assignment by default. All rules are assigned to all instances, but you can assign certain rules to certain instances only for more information on fire world components. Please refer to the link section of this video. Let's look at some G C P. Firewall really use cases for both. Egress and ingress. Egos. Firewall rules control outgoing connections originated inside your G. C. P network eager to allow rules allow outbound connections that match specific protocol ports and I. P addresses. Eagles deny rules, prevent instances from initiating connections that match non permitted port protocol and IP range combinations for egos, firewall rules, destinations to which a rule applies may be specified using IP side arranges specifically. You can use the destination ranges to protect from undesired connections initiated by VM instance towards an external host. As shown on the left. You can also use destination ranges to prevent and desire connections from internal VM instances to specific DCP side arranges. This is illustrated in the middle, where a VM in a specific subnets is shown attempting to connect inappropriately to another VM within the same network. In Greece firewall rules protect against incoming connections to the instance from any source fingers allow rules allow specific protocol ports and IP ranges to connect in the firewall prevents instances from receiving connections on non permitted ports and protocols rules can be restricted to only affect particular sources. Source side arranges can be used to protect an instance from undesired connections come either from external networks or from G C p. IP ranges. This diagram illustrates a VM receiving a connection from an external address and another VM receiving a connection from a VM. Within the same network, you can control english connections from a VM instance by constructing inbound connection conditions using source side arranges protocols or ports.
Pricing

[Autogenerated] before you apply what you just learned. Let's talk about network pricing. It is important that you understand the circumstances in which you are built for GPS network. This table is from the computer and in documentation and it lists the price of each traffic type. First of all, increased traffic coming into GPS network is not charged unless there is a resource such as a load balancer that is processing english traffic responses to requests, account as egress and are charged. The rest of this table lists egress or traffic leaving a virtual machine. Egress traffic to the same zone is not charged as long as that. Egress is through the internal IP address of an instance. Also egos traffic to google products like youtube, maps drive or traffic to a different TCP service within the same region is not charged for. However, there is a charge for egress between zones in the same region. Egress within a zone if the traffic is through the external iP address of an instance and egress between regions. As for the difference in egos, traffic to the same zone compute engine cannot determine the zone of a virtual machine through the external iP address. Therefore, this traffic is treated like eagles between zones in the same region. Also, there are some exceptions and pricing can always change. So refer to the documentation in the link section of these slides. Now you are charged for static and ephemeral external iP addresses. This table represents the external iP pricing for us Central one. As of this recording, you can see that if you reserve a static external iP address and do not assign it to a resource such as a VM instance or a fording rule, you are charged at a higher rate than for static and ephemeral external ip addresses that are in use Also, external iP addresses on preempt Herbal VMS have a lower charge than for standard VM instances. Remember pricing can always change. So please refer to the documentation link in the slides. Also I recommend using the G c p pricing calculator to estimate the cost of a collection of resources because each TCP service has its own pricing model. The pricing calculator is a web based tool that you use to specify the expected consumption of certain services and resources and that then provides you with an estimated cost. For example, you can specify a specific instance type in a specific region along with 100 gigabytes of monthly egos traffic, two Americas and EMEA. The pricing calculator then returns the total estimated cost. You can adjust the currency and timeframe to meet your needs and when you finish you can email the estimate or save it to a specific URL For future reference to use the pricing calculator today, refer to the link in the slides
Lab Intro: VPC Networking

[Autogenerated] Let's apply some of the network features we just discussed in the lab. In this lab, you create an automotive VPC network with firewall rules and to VM instances. Then you convert the automotive network to a customer network and create other custom mode networks. As shown in this network diagram, you also explore the connectivity across networks.
Lab: VPC Networking

Lab Review: VPC Networking

[Autogenerated] in this lab, you explore the default network and determined that you cannot create VM instances without a VPC network. So you created a new automotive BBC network with subnets roots, firewall rules and to VM instances. And tested connectivity for those VM instances because automotive networks aren't recommended for production. You converted the autumn a network to a customer network. Next, you created two more custom mode VPC networks with firewall rules and VM instances using the G C p console and the G cloud command line. Then you test the connectivity across VPC networks which worked when you Pink external I. P addresses but not when you Pink internal I. P addresses. VPC networks are by default isolated private networking domains. Therefore no internal I. P address communication is allowed between networks unless you set up mechanisms such as VPC peering or a VPN connection, you can stay for a lab walkthrough. But remember that CCPS user interface can change so your environment might look slightly different. Alright, so here I am in the GCB Council and the first thing I'm gonna do is I'm just going to explore the default network. So if I on the left hand side, click on the navigation menu and scroll down to vPC network, we will see that this project has a default network. Every project has a default network. Um That is unless you have an organizational policy that prevents this default network from being created. But essentially all the different projects that use through quick laps will always have this. So in here we can see we have a different submit in each of the different regions. All of these are private I. P addresses, I can also go to the routes and these are established automatically with the network. So we can see routes between the subnets as well as to the default route to the internet and we can even look at the firewall rules. The default network comes with some preset firewall rules to allow iCMP traffic from anywhere. Um rdp traffic as well as its its age and then also all protocols and ports within the network. So this is the range of the network. So we also allow all traffic from within the network itself. So let's go ahead and let's actually delete these files rules. I can just check them all right here and delete them and let's just assume that we want to get rid of everything that's been pre created for us and just create our own network instead. So I'm gonna go ahead and delete these. I can look at the status up here, we can see that all for being deleted. I'll update as each is being deleted and once that is done which is now I can head to the network, select the default network. And we're also just going to delete that entire network And once we did late this network we should see that there should be no route without a network because there's no use case for them. So let's just wait for the network to be deleted and then we'll verify that. So we can again see the progress bar up here. That's the leading. You can also hit refresh and this just should just take a couple of seconds. You can see that some of the refreshing some of the subnets are disappearing. It's actually just deleting them all, all these subnets first and then it's getting rid of the network as a whole because the network is really nothing else. And just a combination of subnets so all these subnets have to be deleted. There we go. They're all gone now and now it's just the network itself. Um that is remaining. If I go to routes, we should see that all the routes already gone because without the subnets there's really no need for the routes. And if I go back to the network, we should see that any moment now, the network itself also disappears. There we go. All right. So without a VPc network now, we shouldn't be able to create any VM instances containers or abandon application. Let's actually verify that. I'm going to go to the navigation menu. Go to compute engine and let's just try to create an instance. Just going to create, I'm gonna leave everything as its default. Um If I go actually under networking, we should see that it's going to complain here, click on networking that actually doesn't have a local network available, but let's just click create, see what happens and it does indeed give us an era and point out the fact that this tab has an issue. So we clearly cannot create an instance because we're gonna again, these instances live in networks and without a network can create it. So let's hit cancel. And what we're going to do now is we're going to create our own automotive network. So I'm going to head back to VPC networks and you can pin by the way, um, these services. So I'm just gonna pin VPc network compute engine because we're gonna be going back and forth between these and then within VPC network, we're just not going to create our own network. I can give it a name, I'm gonna use the same name that I have in love instructions, which is my network. Now, I have the option of creating a custom or an automatic. Let's start off by creating an automatic network. So that's going to preset all of the different subnets for us in all the different regions that are available. You can scroll through those and see those all in here and they have a pre um set aside a range, you can expand that side arrange later. Um but again as an auto network, you don't define the actual IP address range. They're also firewall rules that are available. What's interesting here is you see that there's a deny all ingress and and allow all ego spiral rule. So these are here by default and they actually implied you can't even like uncheck them. So these are actually with all networks that you create and you can see that this has the highest party integer, which really means it's the lowest priority. So by default, all ingress traffic is denied and all eagles traffic is allowed unless we create other fire rules to say differently. So if I check all these boxes were now allowing english traffic for these IP ranges and these protocols and ports. So let's go ahead and click create and we're going to wait for that network to be created and then we're going to look at the I. P. Addresses for um two of the different regions and we're gonna create instances in those regions and verify that it's taking those I. P. Addresses so you can see the substance already all populated here. I can monitor the progress also up here. This is really done any second now, I'm actually going to start heading over to compute engine and to create our instances. So let's click create. I'm going to give it a name. My Net U S V M um this is gonna be in U. S. Central one. Specifically the zone C. Uh I don't really need a big machine. We're just doing some testing here. So let me just create a micro that reduces the cost a little bit and I'm going to now click create and then we're going to repeat. You can close this panel over here the same workflow and create an instance in europe. So I'm going to grab the name from the lab instructions for that. I'm going to select the your app West One region, specifically the Zone One C again a micro machine which is just a shared core. And click create for that as well. We can see the U. S. Central one. C machine is already up. We also see the iP uh the internal I. P address that has been provided. Again, there are some reserved I. P addresses. The 0.0 is reserved as well as the 0.1. So in both of these ranges, that 0.2 is the first available address. Now we can verify that these are part of the right sub net. If I click on the zero, I go to the network interface details and here we can see it's part of this sub network. Now the sub network in this case has the same name as a network because this is an auto network. And here we can see that it's part of this range. So 10 on 28 00 slash 20. Let's verify that. And that is correct. We are in there with a dot to and that's verified that the other should be now a 10 1 32.0 slash 20. So again click on x zero, go to the sub network. And we can see that's true. And you can also see here that the uh this address is reserved for the Gateway. Right? So that that way that data was really the first usable address within that range. So now these are on the same network. So let's verify some connectivity between those. I'm going to grab the internal I. P. Address of minor. UVM just copy that and we're going to SSH to this other instance. So again these instances are in two separate regions but in the same network. So we should be able to ping these addresses now. So ____ ping three times using the internal address when you see that this works. This works because we have that allow internal firewall rule that we selected earlier. I can actually repeat the same by using the name of the instance. And you can see that it's taking that name. It's actually has here the fully qualified domain name and it's just um using the I. P. Address for that. So VPC networks have an internal DNS service that allows you to address instances by the DNS names instead of their internal iP addresses. And that's very useful because well this internally peters could change but the name is not going to change. So it's always good to be aware of that that you can use the fully qualified domain name to ping those. All right now we can try this whole thing the other way around let me exit this instance, grab the internal iP address of the instance in the U. S. And SSH to the instance in europe. And we're also going to ping the internal I'm here just here. We can see that works. We could even now try to ping the external I. P. Address. So that's 34 in my case 67 18 18. And that works as well. And the reason that I'm able to ping the external is because I have a firewall rule that allows um ICMP externally and I can verify those again. If I click on the network interface details here, I can see all of the fire world rules and the fact that what filters they have and what protocols imports. All right. So this all works fine. And let's assume that this workflow has worked for us. But now we have decided that we want to convert the Autumn a network that we have to a customer network. Um, so let's go ahead and do that. We're going to go to VPC networks and we're going to click on my network and then we're going to click on edit and we're going to change these something that creation mode from auto to custom and it's safe. Okay? So now we can navigate back, you can see that this is in progress up here. The mode still says. Otto we could have also flipped that here. Let's wait for that to be refreshed. And now we can see um that this mode is not this sub network is now a custom sub net. Okay. So let's say that this has worked so far and now we realized that we need a couple more networks and there's a network diagram in the lab that has to other networks as well as some instances and everything. So let's go ahead and create those. So now we're going to go to create VPc network. We're gonna create the management network. And rather than starting with automatic and converting we're just going to start with the customers net for that. We have to define each of these sub nets. The minimum information we need to provide is a name, the region. So let's select your central one and then the I. P. Address range and then can click done and now I can add if I wanted to another sub net. Um But the other thing that's very interesting about this is I'm creating this right now through the G C. P council but you can also create um networks as well as subnets from the command line using CloudTrail And if I click down here on command line, I'm actually provided with the commands to do that. The first one just creates the network itself. Um you don't have to use the project flag in here. So we could just say g cloud compute networks create the name of the network and the fact that the subject is a custom mode And similarly then we create these subnets, which is network subnets create the name of the subnets at the something itself, the name of the network, the region and the range. Okay, so again, that's the minimal information. Let's just hit click close and create and we'll create the other one from the command line. So it's creating that network and in parallel I can go now activate cultural by clicking up here the right corner. Yes, I want to start using cloud shell and I'm just gonna make this a little bit bigger and once this is up, we're going to use those commands that we just saw to create first a network and this is going to be the Private Net which is also of the mode custom. And once we have that we're going to create two subnets within that network. So you can see by the way in the console, the other network was created. Private net is being created right now here and once that is ready we can add the two subnets to that. So there you go, there's something that it's also telling us, hey, this is a new network. Um you don't have any firewall rules here. Some commands. If you want to create some firewall rules, we'll do that in a second. Um let's just create the stuff that's in here. So first we're going to create one in the US and then we're also going to create one in europe. If you wanted to speed this up, you could actually launch another cloud shell session. Now that the network is up, you could create these subnets sort of in peril, but we're just gonna wait for this to complete and then we'll piece that command in there and you can monitor all of this and the console click refresh, that we see it, it's also completed. It just returns, I've done exactly what you told me. Let's create the other one. apps I didn't copy the command correctly. There we go. This is now in the in europe, specifically your app West one, apps the wrong button there refresh, you can see that's already being created there. Um So we can definitely gonna display all of those in the G. C. P. console You can also, if you click the button over here include shell, you can actually open this in a new window, It's actually opens it in a new tab that where you preserve your real estate, you can keep focusing on the console as well as focusing on CloudTrail So let me actually create some real estate by just clearing this and then _____ command to list all the networks with G. Cod Computer networks list so we can see them three networks. They're all custom. We can dig deeper into this by also listing the sub networks and using these sort by command to sort these by network. So now we'll see my network has a lot of something because it used to be an auto mode and then for management we want something for permanent, we have two subnets. All right, So now we're gonna go create some firewall rules. So let's click on firewall rules up here, you can see the ones already there. Create firewall rule will repeat the same process we did earlier, will first create this using the console and then we'll repeat the firewalls for different network using co-channel So let me give it a name. Let's make sure I select the right network that the firewall rule applies to. Let's just do all instances and for the IP ranges, select all addresses and I'm allowing in this case ICMP, ssh and RdP select me defined ICMP and then 22 for S s H 33 89 for RDP. And now down here I can click on command line, you can see this is one long command. Again, you don't need to define the project. Flags, this g cloud computing files create the name of the rule. The fact that's in Congress party, that is also actually default. We could leave that out importantly, is the name of the network action allows the fall two and then the rules as well as the social rangers. So let's create that in the console and we'll grab the command from the lab instructions to do the same for other network. So here you can see, paste it in and that should now create the other firewall rule for us and we can monitor the firewall rules in here in the console as well as in CloudTrail So we'll run a command to list all the firewall rules in the second. Um so they're all created. If we list them, we can see them all here. If I refresh this, we can also see them right here. All right, so now it's time to create some more instances and then explore the connectivity So let's head back to compute engine. I'm going to create instances in these new networks that created, let me click create instance and I'm actually gonna close CloudTrail for now, or let me just make it smaller. I'm going to provide a name and use Central One C small machine is very fine. And now, importantly I need to expand this option down here to select the right network. We have three options right now and it has actually pre selected that network. That's because from an order it's listed up top. That is correct. So let's click done. And there's again a command line way, there's a lot of information here that we don't need. You'll see that the second we run our command the boot disk, we're selecting a lot of standard options. So let's just create and let's pull the command from the lab that creates the same in a different network and that's _____ computer instance, create the name of the instance, the zone, the machine type, the submit that is the bare minimum that we need to provide. So let's run that. You can see the other instances already created, I can refresh this, see that the other instances already coming up to. And then once CloudTrail is updated, we can list all the instances. Let's do that here. Consortium by zone or we could sort them by network so we can see in one zone here we have an instance and then in uh another thing we have three instances now keep in mind these instances are in different networks and we can display that if we go to columns and check network, you can see that these instances with exception of the mine it these are the same BBC network, the others are indifferent and that's going to now go into the connectivity that we're going to explore. We're going to try to again ping I. P addresses, both external internal and see what works. So let me grab the management US VM external I. P address and we're going to assess age to the minute US VM. Now they are in the same zone but they're in different networks. So let's see if we can ping the extra I. P address and then we'll try the internal so external works. That's because we set up the firewall rules for that. But if I now and I can also do the same for private net, complete that I. P. Address in which is 35 on any and on a to 20 networks as well. Okay. So you can pick those even though I don't different networks now from an internal perspective, I should only be able to ping mine at UVM which we actually tried earlier. Ready. So let me just hop on the other ones. When I try 10 1 30 that's 02 We can see that that's not leading to anything. We should be getting 100% packet loss and then we'll try the same from the other one. Yeah. So 1 72 about 16 02 And we can see that that again isn't working either. Right? So even though this instance is in the same zone as these other instances, I'm trying to ping the fact that they are in a different network does not allow me to ping on the internal IP unless we set up other mechanisms, such as VPC peering or a VPN, and that's the end of the lab.
Common network designs

[Autogenerated] Let's use what we have learned so far and look at common network designs. Now, common is a fairly relative term. While I could spend all day talking about network designs, I have picked a handful of designs that best relate to this module. Let's start by looking at availability. If your application needs increased availability, you can place to virtual machines into multiple zones. But within the same sub network as shown on this slide, using a single sub network allows you to create a file rule against the sub network in this case 10.2 dot 00 slash 16. Therefore, by allocating VMS on a single submit to separate zones, you get improved availability without additional security complexity. A regional managed instance group contains instances from multiple zones across the same region, which provides increased availability. Next let's look at globalization in the previous design, we place resources in different zones in a single region, which provides isolation for many types of infrastructure, hardware and software failures. Putting resources in different regions as shown on this slide provides an even higher degree of failure independence. This allows you to design robust systems with resources spread across different failure domains when using a global load balancer, like the HTTP load balancer, you can route traffic to the region that is closest to the user disk and result in better latency for users and lower network traffic costs for your project. We'll explore both managed instance groups and load balancers later in this course series. Now as a general security best practice, I recommend only assigning internal IP addresses to your VM instances whenever possible. Cloud net is google's manage network address translation service. It lets you provision your application instances without public IP addresses while also allowing them to access the Internet in a controlled and efficient manner. This means your private instances can access the internet for updates, patching, configuration management and more in this diagram. Cloud Net enables to private instances to access and update server on the internet which is referred to as outbound net. However, Cloud net does not implement inbound net. In other words, hosts outside your VPC network cannot directly access any of the private instances behind the cloud Net Gateway. This helps you keep your VPC networks isolated and secure. Similarly. You should enable private google access to allow VM instances that only have internal IP addresses to reach the external iP addresses of google apps and services. For example, if your private VM instance needs to access a cloud storage bucket, you need to enable private google access, you and a private google access on a submit by submit basis. As you can see you in this diagram submit a has private google access enabled and submit b has a disabled. This allows VM one to access google apps and services, even though it has no external iP address. Private google access has no effect on instances that have external IP addresses. That's why VMS A two and B two can access google apps and services. The only VM that can't access those EPAS and services is V M B one. This VM has no public IP address and it is in a submit where google private access is disabled.
Lab Intro: Implement Private Google Access and Cloud NAT

[Autogenerated] Let's apply what we just covered in this lab. You implement private google axis and Cloud net. For a VM instance, that doesn't have an external I. P. Address. Then you verify access to public I. P. Addresses of google APIs and services and other connections to the Internet.
Lab: Implement Private Google Access and Cloud NAT

Lab Review: Implement Private Google Access and Cloud NAT

[Autogenerated] in this lab, you created an instance with no external I. P. Address and access it using cloud app You then enable private google access and configured in that gateway and verify that VM internal can access google a PS and services and other public I. P addresses. VM instances without external I. P addresses are isolated from external networks using cloud. Not these instances can access the internet for updates and patches. And in some cases for bootstrapping as a managed service. Cloud net provides high availability without user management and intervention. Let me walk you through the lab now remember that the G. C. P user interface can change so your environment might look slightly different. So the first thing I'm going to do is create the VM instance and for that we're also going to have to create a VPc network and some firewall rules. So let me go to navigation menu, scroll down to VPC networks and we're going to create a network and call it Private net. So I'm going to give a name. Private net. Keep the submit creation mode as custom and we're just going to create one something in here. We're going to call private, let us those places in the U. S. Central one region as given to us in the instructions here we come and we even have an iP address range for that. Now. We're gonna enable private google access later. So you want to keep that off for now so that you can see what's and they're turned on by accident so you can see the effect of it being off. So let me click done and click create. I'm going to wait for this network to be created and once it's up and running we're going to add a firewall rule because we want to allow SSH to the instance that we're going to put on this network so I can see the network here. A firewall rules created four networks so I had to wait for that to be ready. So let me go to file rules quantifiable role. Give it a name, specify that the network is private net. Let's just to all instances and sort by iP ranges now rather than just saying, hey, you can SSH this instance from anywhere. We are actually going to give it a very specific range. And this is because we're using cloud IP so we're going to use a cloud IP tunnel and because of that we can limit the side arrange. Now this is for an ssh connection. So I want to enable TCP report 2020 and I mean 22 and then click create and while this is creating, I can go ahead and create my compute engine instance. Let's go to compute engine, click create, we're gonna give it the name VM. Internal. We need to make sure we choose a region that is actually for which we have created. Sub Net. So your central one so you're central one. C I can keep the machine type as my standard and once they at 11 virtual CPU and I'm going to scroll down. The important thing is I need to select the actual BBC network. So let's go to networking, I'm not working again. I'm going to edit the network interfaces. I want to select the private Net network. It only has one sub net and I'm going to set the external I. P. Address to none and click done and click create. So this there's a way to create an instance of private instance. Let me close this that has no external I. P. Address. Now when the instance comes up you will see that we won't be able to directly SSH to it because it doesn't have and external iP address. So if we use this this wouldn't work on us. So instead what we're going to use is we're going to do and um IP tunnel for that, we're going to open cloud shell so let me go activate CloudTrail and that popped up in a new window. That can certainly happen sometimes it looks like there's some A B testing going on here. So here I have cloud shell doesn't look like it has the correct project set. So let's actually do that. I'm going to set the project and then just crab the project ID from here and set this up for the correct project and then we can see that now. Okay so it's set up and now what I'm going to do is I'm going to run the command to SSH from here and we'll specify this is through hip and then I want to confirm, okay, um for pass rates which is going to enter and then enter again and then once this is complete, we should now see that the command prompt has changed to VM internal. So we're now in the maternal, it doesn't have an external API address. But let's confirm that we can't just pick the World wide web. Right. And this ping command isn't working because VM internal does not have an external I. P address so we can wait for this to complete and it's failing again, when instances don't have external iP addresses, they can only be reached by other instances on the network. Either through a managed VPN gateway or cloud iP tunnel and cloud iP enables context where access to BMS through Ssh and RDP without a bastion host. That would be the other idea or option. We could create a bastion host but that would still have an external API and we're just using the patch notes to then connect to this. Instead, we can just use CloudTrail and IP so this isn't working. So what we're going to now is we're going to look into private google access. So currently the um, instance with no external IP address can use private google access to reach external I P addresses of google, a PS and services but by default this is disabled, we saw that earlier. We left. That is disabled. So let's test the effect of this being disabled. I'm going to go to the navigation menu and we're going to create a cloud storage bucket so let's go to storage and we're gonna click create pocket. Now the most difficult pieces, you need to have a unique pocket name. You can do that by grabbing the IDE project to continue. You can leave this as multi region, we can leave everything else by default and just click create. The important thing is you're gonna have to remember that bucket name. So here's the bucket. So I'm going to do now is I'm going to go back to cloud shell and importantly I'm still in my VM instance here. Okay, so I want to change that so let me exit out of here. So now I'm back in collateral and then I'm going to run a command to copy an image from a public bucket to my bucket, but I need to specify what my bucket is so I can take the name of the bucket. Yeah. And at that here to copy this image so that worked and we can go in here and refresh to verify that we now have an image in here and you can actually click on this image and it's just um shows you how private google axis is implemented depending if it's on or off for a network, we're going to explore that a little bit more. So now what we're going to do is we're going to now try to copy this image first from Cultural. Well CloudTrail has an external IP address so that is going to work, run that. Mhm Yeah and you took actually click enter and obviously I didn't specify my pocket that is on me. It's only two. Change my pocket. So typical area that you might see let me grab the name of the bucket, place them in there. Let's try that again. Okay, that works. I mean we even use classical to move this image anyway, so we're able to access cloud storage currently through CloudTrail Let's go back to our VM Internal instance to So we use the same commander used earlier to SSH through a IP tunnel here, I can see the command prompt change and now I'm just going to try, I'm just going to copy the same command here to copy this image, so I don't have to copy the change the bucket name in a couple of times, I'm not going to run that and we should see that this does not work because currently VM Internal can only send traffic within the VPC network because again, private google access is disabled. So two options we can wait for this to fail and give us an error or we can use control C to just stop the request. So it's actually just stop this. And when we do now is I'm going to Evil private google axis, so let's go back to decode console, the navigation menu and I'm going to navigate to my VPC network, specifically Private net and private google access is enabled at the Sublette level so I'm going to go directly to the submit, click the edit icon scroll down, enable private google accessor soto on click safe, I'm going to wait for this to update and then I'm going to come back two my instance, my SSH lessons through cloud shell and just try to run the command again, it looks like it's all set, you can also see that here go back to my SSH window, Run that command again and how it works. Okay, so that's how easy it is to enable private google axis. So now in this last task of the lab we're going to configure a cloud nat gateway, although our instance here of um internal can now access certain google APIs and services without an external iP address. The instance cannot access the internet for updates and patches so for that we're going to good figure oclock gateway but again we're going to try this behavior first without the nat gateway and then we're going to enable it. So what we're going to do is I'm going to exit here to just get to my cloud shell instance. There we go, I can see the command prompt change to CloudTrail and I'm just going to run Sudo apt, get update and that should obviously work for Michael actual instance because it has an external iP address so we can see it's getting all these packages and that is working just fine. So now there's complete, we're gonna use the ssh command again using the tunnel to get to VM internal that we can see this change and now we're gonna run the same command here. You know, you might say, well, hold on. Is actually able to get some of these packages. Yes, that's because we've enabled private google axes, so it's able to get those within google and once it's trying to get something else here, it's failing. Okay. So we can just stop that, this is not going to happen. And now we're going to go ahead and configure a cloud gateway and then try to run that command again. So let's go to the cloud council and under the navigation menu, we're going to go to network services and continent. We're going to get started. Just give this a name called Net conflict and that's just the name that we have in the lab instructions. You really want to follow these lab instructions because any of our labs that are scored will use the names that were defining in the lab instructions So important this needs to be on private net region is US central one. And for cloud router we currently don't have one. So we're going to go create one. This is super simple. You just give it a name and to create now there's also a net mapping section and this allows you to choose these subnets to map to the Net gateway. So you could manually assign static I. P addresses that should be used when performing that. But in this case we're not going to go get that fancy. We're just going to click create and we're going to wait now for the gateway status to change to running so we can see that the status changed the running. It actually only took a couple seconds now, even though this is running, it may actually take up to three minutes for the nat configuration to propagate all the way to the PM. So you want to wait at least a minute before trying to access the internet again. What I mean by that is in our ssh session that we currently still have to VM internal. We're going to run the command again. I want to make sure it works this time so I could actually just try it right now and see if it's ready or not. And if I do you see it's still failing at this step. So let me hit control C and let's wait a couple more minutes and then try to run the command again. Hi. So we waited a couple of minutes. Let's try to run the command one more time and now we can see that it's working. It's getting all the packages and with that we can confirm that cloud not declining. Gateway is not working a couple of things to remember. The clarinet Gateway implements, outbound net but not in .NET Other words, what that means is that hosts outside of your VPC network can only respond to connections initiated by your instances. They cannot initiate their own so new connections to your instances beer than that. So keep that in mind. The other thing is in this lab we used IP and IP uses your existing project roles and permissions when you connect to VM instances. So by the fault instance owners which you're an instance owner since you created this instance, they're the only ones that have the IP secure tunnel user role and if you want to lower other users to connect to access using VMS using IP telling you need to grant them those roles and you can actually do that directly through the navigation menu and go to cloud IP and just give people those roles. That's the end of the lab
Module Review

[Autogenerated] In this module, I gave you an overview of google's virtual private cloud. We looked at the different objects within VPC like projects, networks, iP addresses, routes and firewall rules. I also provided a brief overview of how your network design choices can affect building. Then you apply the different concepts that we covered in a thorough lab. Next, we looked at common network designs and you got to implement private google axis and cloud net in the lab. Now that you have a solid understanding of how g C P has implemented networking, let's move on to learn more about other services. Next up is compute Engine, which offers scalable, high performance virtual machines.
Virtual Machines
Module Overview

[Autogenerated] in this module we cover virtual machine instances or volumes. VPNs are the most common infrastructure component and NGC P. They're provided by compute engine. A VM is similar but not identical to a hardware. Computer. VMS consists of a virtual CPU some amount of memory disk storage and an IP address compute engine is G C P service to create VMS. It is very flexible and offers many options, including some that can't exist in physical hardware. For example, a micro Veum shares a CPU with other virtual machines so you can get a VM with less capacity at a lower cost. Another example of a function that can't exist in hardware is that some VMS of a burst capability, meaning that the virtual CPU will run above its rated capacity for a brief period using the available shared physical CPU, the main VM options are CPU memory disks and networking. Now this is going to be a very robust module, There's a lot of detail to cover here with how virtual machines work on G. C. P. First. We'll start with the basics of compute engine, followed by a quick little lab to get you more familiar with creating virtual machines. Then we'll look at the different CPU and memory options that enable you to create different configurations. Next, we'll look at images and the different disk options available with compute engine. After that, we will discuss very common compute engine actions that you might encounter in your day to day job. This will be followed by an in depth lab that explores many of the features and services covered in this module. Let's get started with an overview of compute engine.
Compute Engine

[Autogenerated] as I mentioned in the introduction to the course, there is a spectrum of different options in GDP for compute and processing. We will focus on the traditional virtual machine instances. Now, the difference is computer engine gives you the utmost inflexibility, run whatever language you want. It's your virtual machine. This is purely an infrastructure as a service or I A S model, you have a VM and an operating system and you can choose how to manage it and how to handle aspects such as auto scaling, where you will configure the rules about adding more virtual machines in specific situations. Auto scaling will be covered in a later course of this series. The primary work case of computer engine is any general workload, especially in enterprise application that was designed to run on a server infrastructure. This makes computer engine very portable and easy to run in the cloud. Other services like google kubernetes engine, which consists of continuous workloads, may not be as easily transferable as what you're used to fund on premises. So what does compute engine at its heart? Its physical servers that you're used to running inside the G C. P environment with a number of different configurations. Both predefined and custom machine types allow you to choose how much memory and how much CPU you want. Do you choose the type of disk you want? What do you want to just use standard hard drives? SSD s, local SSD S or M. X. You can even configure the networking interfaces and run a combination of Linux and Windows machines. Several different features will be covered throughout this module, such as machine, right, Sizing, startup scripts, metadata, availability policies and pressing and usage discounts. Let's start by looking at the computer options, compute engine provides several different machine types that will discuss later in this module. If those machines don't meet your needs, you can also customize your own machine. Your choice of CPU will affect your network throughput. Specifically, your network will scale at two gigabits per second for each CPU core, except for instances with two and four virtual Cpus which received up to 10 gigabits per second of bandwidth. As of this recording, there's a theoretical maximum throughput of 32 gigabits per second. For instance with 16 or more Cpus and a 100 gigabits per second. Maximum throughput for specific instances that have T four of the 100 Gpus attached. When you're migrating from an on premises setup, you're used to physical course which have hyper threading on computer engine. Each virtual CPU or V. C. P. U. Is implemented as a single hardware. Hyper thread on one of the available CPU platforms. For an up to date list of all the available CPU platforms refer to the link section of this video. After you pick your computer options, you want to choose your disk, you have three options. Standard SSD or Local SSD. So basically do you want the standard spending hard disk drives or hDgs or flash memory? Solid state drives? SSD s. Both of these options provide the same amount of capacity in terms of disk size when choosing a persistent disk. Therefore the question really is about performance versus cost because there is a different pricing structure. Basically S. S. D. S are designed to give you a higher number of IOPS per dollar versus standard disks, which will give you a higher amount of capacity for your dollar. Local SSD s have even higher throughput and lower latency than SSD persistent disks because there are attached to the physical hardware. However, the data that you store on local SSD s persists only until you stop or delete the instance. Typically a local SSD is used as a swap. This just like you would do if you want to create a round disk, but if you need more capacity you can store those on a local SSD. You can create instances with up to eight separate 375 gigabytes. Local SSD partitions for a total of three terabytes of local SSD space for each instance, standard and non local SSD disks can be sized up to 64 terabytes for each instance, the performance of these disks scales with each gigabyte of space allocated as for networking we've already seen networking features apply to computer engine in the previous modules. Lab, we looked at the different types of networks and created firewall rules using iP addresses and network tags. You'll also notice that you can do regional HTTPS load balancing and network load balancing. This doesn't require any pre warming because a load balancer isn't a hardware device that needs to analyze your traffic. A load balancer is essentially a set of traffic engineering rules. There are coming into the google network, and BBC is applying the rules destined for your IP address subnet range. We'll learn more about load balances in a later course of the architect, in with google compute engine series.
Demo: Create a VM

[Autogenerated] let me give you a quick walk through of the VM instance creation process and point out CPU storage and network options in the G c p console So here I am already on the compute Engine instance page you can get to here by going to the navigation menu and then clicking on compute engine and as we use this in the course a lot, you might actually want to pin this sometimes so that you can get to it more easily and then within their, I have gone into VM instances. So I just want to again show you some of the options that are available when creating instance to get started. I'm going to click on create and the first thing I want to choose is a name, so you have to write up here and then maybe more importantly is actually where you want the instance to be located. So you have the option of all the different available regions. It has the name of the regions as well as the closest city as to where that region is located. And then within the regions you have different zones that you can choose from. You also see on the right hand side that there is a cost associated with the current configuration. And that cost is going to change as we change the configuration. So for example, if I instead of creating an instance in U. S. Central one, I create one maybe in europe West one, you will see that the cost is slightly adjusted so I can try that a couple different ways by choosing different locations and you should see that the cost changes depending on the region that we choose now it goes further. If I then choose the machine type. Um There are different types will go into all of those. Um But if I go in here, the different types explain to me what they provide this standard and one standard one provides one virtual CPU with 3.75 gigabytes of memory. If I change to a machine with more CPU and more memory will see that the cost is adjusted. You can also go into details here. It actually spells it out for you that there's a cost for the CPU and memory, but there's also a cost for the persistent disk. We haven't configured that yet, but this is the default value and if we can figure that it's going to adjust the cost. There's also sustained use discount, we'll go into that as well. But essentially all of that is what ultimately gets you to this total monthly cost. Um It's also broken down in an hourly cost here and we'll talk more about pricing later within the module. So again, I can choose different machine types and we want a larger machine type, it's going to be more expensive. Maybe I just need a shared core. So something really a micro machine or a small machine and that can really drive the cost down a lot. So let me go back to the default. And um the other thing to think about in terms of your region and zone is not just the cost, but really um you know, you want to create your instances that are close to users, uh maybe you want to have them spread out across different regions for high availability, you might be have restrictions for data locality, meaning that your data has to be in a specific region. So these are all the different things that you want to consider when choosing the region and zone. Now, if I scroll further down one of the next big options is the boot disk. So we can see here that currently it has a 10 gigabit. By standard persistent disk, I can change that. I can change the image itself but I can also change the boot this type now the boot disk needs to be a persistent disk, we have the standard persistent disk, think of an HDD and we have the SSD and you can see that we have we can define the size here and you can see that both of them have the same exact maximum size. So if I make this larger, let's say 1000 and we're going to see that the cost now is adjusted to that disk size so I can go back that's very large. Maybe I'm just okay with 10 occupied as the boot disk. You can also add more disks. So if I scroll down and go to management security, this networking, I can go to disks here. So here I can choose the type of encryption for the disk. I have google managed key, customer managed key, customer supplied key and then I can add more disks. So if I add a new disk here than on the type, I could also choose a local SSD. These come in predefined sizes um depending on how many you choose your performance as you can see down here is going to get adjusted. There is a limit so at some point did larger um the more disk you choose, you're going to hit a limit in terms of your performance and same if I choose you on an SSD disk and change the size here, you'll see that also there's a limit but it's also adjusted. If I scale this, you are changing the IOPS as well as the sustained throughput limit. Now, another important thing is obviously networking. So if I click on here, you want to choose the network interface. Uh we already went into this a little bit in the previous module. In terms of your choosing your primary internal IP choosing if you want an external IP or not. So those are all of the different options that you can get there. Now what's really cool is this is all using the gCB console but down the road you might say well I want to create these instances quickly and I want to use the command line. Well, this user interface gives you the command line options so it's spelling out exactly all the different options you have chosen, how you would recreate that using the cloud. So this can help you get started using that command line and make you more comfortable using that command line. Yeah, So let me just go ahead and create this instance. And once we created we have these different columns that are listed here. There are more columns that we can choose from, for example, when you created it, what the machine type is, what network this is a part of if you had labels or other things. So lots of different jobs. And you can list here, for example, I can list here when the machine was created the type as well as the network. It is a part of that's how easy it is to configure the location, CPU memory storage and network interface for a VM instance using the G c p console Let's get back to the slides to go over VM access and lifecycle
VM access and lifecycle

[Autogenerated] for accessing A VM. The creator of an instance has full root privileges on that instance on a Linux instance, the creator has SSH capability and can use the G C p. console to Grant SSH capability to other users on a Windows instance, the creator can use the G c p console to generate a user name and password after that. Anyone who knows the user name and password can connect to the instance using a remote desktop protocol or RdP client. I listed the required firewall rules for both Ssh and RdP here, but you don't need to define these if you're using the default network that we covered in the previous module. For more information on Ssh key management and creating passwords for Windows instances refer to the link section of this video. The life cycle of a VM is represented by different statuses. I will cover this lifecycle on a high level but I recommend returning to this diagram as a reference when you define all the properties of an instance and click, create the instance, enters the provisions state here. The resources such as CPU memory and disks are being reserved for the instance by the instance itself isn't running yet. Next. The instant moves to the staging state where resources have been acquired and the instance is prepared for launch specifically in this state, compute engine is adding iP addresses, booting up the system image and booting up the system after the instance starts running, it will go through pre configured startup scripts and enable Ssh or RdP access. Now you can do several things while you're instances running. For example, you can live migrate your virtual machine to another host in the same zone instead of requiring your instance to be rebooted. This allows G c p to perform maintenance is integral to keeping the infrastructure protected and reliable without interrupting any of your dreams. While you're instances running, you can also move your VM to a different zone, take a snapshot of the VMS, persistent disk, export the system image or reconfigure metadata. We will explore some of these tasks in later labs. Some actions require you to stop your virtual machine. For example, if you want to upgrade your machine by adding more CPU. When the instance enters the state, it will go through pre configured shutdown scripts and end in the terminated state from the state. You can choose to either resort instance, which would bring it back to its provisions state or delete it. You also have the option to reset of um which is similar to pressing the reset button on your computer. This action wipes the memory content of the machine and resets the virtual machine to its initial state. The instance remains in the running state. Throughout the reset, there are different ways you can change a VM state from running. Some methods involve the G C P. console and the _____ command. While others are performed from the OS such as for a reboot and shutdown. It's important to know that if you're restarting, rebooting, stopping or even deleting an instance, the shutdown process will take about 90 seconds for a preemptive VM. If the instance does not stop after 30 seconds, compute engine sends an ACP three mechanical off signal to the operating system. Remember that one writing shutdown scripts for preemptive All VMS as I mentioned previously compute engine can live migrate your virtual machine to another host due to a maintenance event. To prevent your applications from experiencing disruptions. VMS availability policy determines how the instance behaves in such an event. The default maintenance behavior for instances is to live migrate, but you can change the behavior to terminate your instance during maintenance events. Instead, if your VM is terminated due to a _____ or other maintenance event, your instance automatically research by default, but this can also be changed. These availability policies can be configured both during the instance creation and while in instances running by configuring the automatic restart and on host maintenance options. For more information on live migration, refer to the link section of this video. When a VM is terminated, you do not pay for memory and CPU resources. However, you are charged for any attached disks and reserved iP addresses in the terminated state. You can perform any of the actions listed here, such as changing the machine type, but you cannot change the image of a stop. VM Also, not all of the actions listed here require you to stop a virtual machine. For example, VM availability policies can be changed while the VM is running as discussed previously.
Lab Intro: Creating virtual machines

[Autogenerated] Let's take some of the compute engine concerts we just discussed and apply them. In the lab. In this lab, you explore virtual machine instance options by creating several standard volumes and a custom beer. You also connect to those VMS, using both SSH for Linux machines and RDP for Windows machines.
Lab: Creating Virtual Machines

Lab Review: Creating virtual machines

[Autogenerated] in this lab, you created several virtual machine instances of different types with different characteristics. Specifically, you created a small utility VM for administration purposes. A Windows VM and a custom Linux via You also access both the Windows and Linux KVM and deleted all your Creative VPNs in general. Start with a smaller VM. When your prototyping solutions to keep the costs down when you're ready for production trade up to larger VMS based on capacity. If you're building in redundancy for availability, remember to allocate excess capacity to meet performance requirements. Finally, consider using custom VMS. When your applications requirements fit between the features of these standard types, you can stay for a lab walkthrough, but remember that GPS user interface can change so your environment might look slightly different. So in the G C P council, I'm going to navigate to compute engine and then VM instances and in here we're going to click create now, we can define a name. There's a small question mark here and if you have already can tell a little bit more about some of the restrictions you have in regards to creating a name, choosing a name that is and I'm just going to call this my utility BM. And we're going to go with some of the options that actually went over a little bit in the demo but we obviously can choose regions and zones changed zone to what the lab is instructing, which is one C. And then for the machine type, we have a lot of different options to choose from. We can see that the cost changes. If I scale up to a machine with four virtual Cpus versus a machine that's just maybe a micro which is a shared core machine. So the cost can change quite drastically. So let's just leave all the remaining settings and click create. And once the machine is up and running, we're going to explore the different VM details that we have. So we're going to go into the VM instances page and look at things like the CPU platform, the availability policies and so on. So let me do that. Let me click on utility um because it's now in a running state and I'm going to look for CPU platform, you can see that right here and if I click edit you'll see that. Actually I'm unable to modify that. Okay, so that's because I can't do that while the instances running there are other things I could do, I could change the firewall rules, I can add network tags. So certain things are available to change while in instances running in some cases you have to stop the instance to change some of the properties. In other cases, you cannot actually even change it unless you delete it. Uh One of those is, for example, the network interfaces, if you have multiple network interfaces, you'd have to recreate your instance. The good thing is you could keep your boot disk and just reattach that boot disk later on. Now. I can also go look at the availability policies so it's cool down talking about what the on house maintenance is by default, it's set to migrate the VM instance and that's recommended. But you could set this to terminate the instance and it's also going to automatically restart that instance. So you could configure that as well. So this is just a little bit exploring the different options. I'm going to go click cancel and what we're going to do now is explore some of the VM logs. So if I'm looking at the detail page here, we want to get a little bit more information about the monitoring options are available. We can click monitoring here and we'll get more information about the CPU this instance is barely run so we don't have much data yet. We get information about the network bytes and packets. This guy. Oh and we can also, if we go back to details, look at stack driver logging. So this is now a different user interface and here we now have individual logs that we can explore and we can view options here. We could expand all of these and dig into all of these different logs that are in here and even within their, expand each of the logs to get more information. So this uses sector over logging will cover the speech a little bit more in a later course in the course series. If you're interested to learn more about both the logging piece that we just looked at as well as the monitoring. So let's go to test two. We're now going to create a Windows virtual machine. So I'm going to go back through the navigation menu compute engine to VM instances and I'm not going to create another instance, so I'm going to define a name and this is just going to call the Windows VM and we're going to choose a different region and zone this time. Why don't we put this into europe west to and specifically designed to a let's pick a larger machine. Let's pick one that has to virtual Cpus and 7.5 gigabytes of memory. And we can even go ahead now and change the boot disk because by default this would be a Linux machine. So if we want to change this because we want to create a Windows machine and specifically the lab is instructing me to look for the Windows server 2016 data center core image. It's for scroll down, see that image right here can change the boot disk. Maybe I want some higher IOPS I can choose an SSD and I can even make this larger and click select and all of that again is going to affect obviously the cost. I have the cost of the machine, I have the cost of the disk. But the new thing I have now also is the image. I've chosen the premium which means there's a cost associated with using that image but it's built all together for you. So you can see that cost broken up right here. Now the other thing we're going to do is we're going to allow specific traffic, http and https traffic. This just creates a network tag for us and then creates file rules on that network tag so that we can enable traffic on those ports for the TCP protocol. So let's hit create and create this instance. And one thing we'll notice when the instance comes up is that under the connect column rather than now seeing an SSH button, which is what we would have for a Linux machine. We should now see an RdP which is for the remote desktop protocol. And so that's how you would access a Windows machine. Now the important thing is there, you obviously want to configure your username and password. Um so that only authorized users access um that machine. So here you can see the RdP button now. And what we're going to do now is we're going to click onto the machine and set the Windows password. You can actually also do this by clicking down here. You can set Windows password there as well. So actually let's just do it that way. And so you have a user name here, it's taking the user name that I have um for my lab account. So this is the user name right now. So I can set that and then it's going to be provide me with a password. So there we go. So I could now copy that password and if I use an RdP connection, I can then get into that. This is a little bit outside of the scope for this lab. But if you want to and have an already declined, you can actually install one through Chrome through an extension. You could access that instance that way and then configure. I didn't do anything else you wanted to in this Windows virtual machine. So let me go ahead and close that. And I'm going to move on to a task three now, which is to create a custom virtual machine. So I'm going to go back to create instance and to find a name which is called my customer. Bm. Um Follow the lab instructions here for setting the region and zone which is us west one beat. And now rather than choosing a specific machine type, I can go in here and just select custom as the machine type and then define the exact numbers. Of course a memory. So let's say my specifications are I want six virtual CPU and you can see how the scales. By the way, there are only certain options you can choose and goes all the way to 96. So let me choose six here. It's going to scale that memory automatically force it gives us a range. Now depending on that CPU there's an option to extend the memories. So you could get more than 39. See all the way to 624. And this is a separate option. We'll talk more about this in the slides so let me choose 32. And rather than scrolling here, I could also just type the value in and and that's also gonna adjust the cost. Now. Now sometimes it's important to note that your custom machine maybe between two machine types are actually already provided. The custom machine is generally going to be slightly more expensive. Um So if you have a custom a standard machine that's very close to the custom machine, it's definitely something you would want to consider and once the machine runs more than 24 hours you'll get right sides recommendations. So I'll tell you if the machine is too small or too large and make recommendations based on that, let's go ahead and create that. And once it's up and running, we're going to SSH to the machine and we're going to run some commands on that machine. And that's actually going to wrap up the lab for us. Now with any new project, you get this column here on the right hand side to help you get started because we're using quick labs generated projects. There are always going to be new project. So you'll see this throughout the training. You can certainly leverage this if you want, but I'm gonna collapse that. All right. So VM is up and running. Let me SSH to it. And then we're going to run the free command to see information about any unused unused memory and swap space. So let me type free so we can see that here and that lines up with the memory selections that we made in the machine. I can also see get more information or details about the RAM installed. Okay. So here we get more information about that as well. Okay. And I can verify the number of processors, so that should have been six and yep. And process sixth grade, we can see details about the CPU itself. So here we get information about the architecture at the right order which model, exactly. So you can get all this information about any VM that you create. And you can also get more information about this in the documentation depending on which region and zone you choose. You'll have different architectures and different models available to choose from. Okay, So that's all we wanted to show you here with this lab. Um You went ahead and created that virtual machine, the utility VM. We created a Windows VM. And then we created a custom virtual machines and verified that whatever custom settings we applied, um we're actually used to create the machine by running commands within that machine.
Compute options

[Autogenerated] now that you have completed the lab. Let's dive deeper into the computer options that are available to UNDCP by focusing on CPU and memory. You have three options for creating and configuring a VM. You can use the G C p. console as you did in the previous lab, the cloud shell command line or the Restful Api. If you'd like to automate and process very complex configurations, you might want to programmatically configure these through the restful api by defining all the different options for your environment. If you plan on using the command line or restful Api I recommend that you first configure the instance through the G C p console and then ask compute engine for the equivalent rest request or command line as I showed you in my demo earlier. This way you avoid any typos and get drop down lists of all the available CPU and memory options. Speaking of CPU memory options, let's look at all the different machine types that are currently available. A machine type specifies a particular collection of virtual hardware resources available to a VM instance including the system memory size V. CPU count and maximum persistent dis capability G C P offers several machine types that can be grouped into two categories. Predefined machine types. These have fixed collection of resources are managed by compute engine and are available in multiple different classes. Each class has a predefined Rachel of gigabytes of memory per virtual CPU. These are the standard machine types. High memory, high CPU memory optimized, compute optimized and shared core machine types. They're also the custom machine types and these let you specify the number of virtual CPU's and the amount of memory for your instance. Let's explore each of these machine types. But remember that these machine types and the available options can change. Standard machine types are suitable for tasks that have a balance of CPU and memory needs. Standard machine types have 3.75 gigabytes of memory per virtual CPU. The virtual CPU configurations come in different intervals from one V CPU all the way to 96 V Cpus. As shown on this table. Each of these machine supports a maximum of 128 persistent disks with a total persistent disk size of 64 terabytes. Which is also the case for the high memory. High CPU memory optimized and compute optimized machine types. High memory machine types are ideal for tasks that require more memory relative to V C p U S. High memory machine types have 6.5 gigabytes of system memory pervy CPU similar to the stent machine types. The V CPU configurations come in different intervals from two V C PS all the way to 96 V C PS. As shown on this table. High CPU machine types are ideal for tasks that require more V Cpus relative to memory. High CPU machine types have 0.9 gigabytes of memory. Pervy CPU memory optimized machine types are ideal for tasks that require intensive use of memory with higher memory to V C. P ratios than high memory machine types. These machine types are perfectly suited for in memory databases and in memory analytics such as s app HANA and business warehouse workloads, genomic analysis and SQL analysis services. Memory optimized machine types have more than 14 gigabytes of memory. Pervy CPU. These machines come in four configurations as shown in this table with only the N one mega meme 96 supporting a local SSD as of this recording, compute optimized machine types are ideal for compute intensive workloads. These machine types are for the highest performance per core on compute engine built on the latest generation intel scalable processors, the cascade Lake C two machine types offer up to 3.8 gigahertz sustained all core turbo and provide full transparency into the architecture of the underlying server platforms enabling advanced performance tuning C. Two machine types offer much more computing power run on a newer platform and are generally more robust for compute intensive workloads than the N one high CPU machine types, shared core machine types provide one virtual CPU that is allowed to run for a portion of the time on a single hardware, Hyper-V threat on the host. CPU running your instance, shared core instances can be more cost effective for running small, non resource intensive applications than other machine types. There are only two shared core machine types of truth from there are the F one micro and the G one small. The F one micro machine types of are bursting capabilities that allow instances to use additional physical CPU. For short periods of time bursting happens automatically when your instance requires more physical CPU than you originally allocated during these spikes. Your instance will opportunistically take advantage of available physical CPU and bursts. Note that births are not permanent and are only possible periodically for up to date information. But all of these machine types see the links section of this video. If none of the predefined machine types matter needs, you can independently specify the number of the Cpus and the amount of memory for your instance. Custom machine tests are ideal for the falling scenarios when you have workloads that are not a good fit for the predefined machine types that are available to you or when you have workloads that require more processing power or more memory, but you don't need all of the upgrades that are provided by the next larger Predefined machine type. It costs slightly more to use a custom machine type than equivalent. Predefined machine type and there are still some limitations in the amount of memory and V C P U. S. You can select only machine tabs with one virtual CPU or an even number of virtual Cpus can be created. Memory must be between 0.9 gigabytes and 6.5 gigabytes per virtual CPU. By default, the total memory of the instance must be a multiple of 256 megabytes by default, a custom machine can have up to 6.5 gigabytes of memory per virtual CPU. However, this might not be enough memory for your workload. So at an additional cost you can get more memory per virtual CPU beyond the 6.5 gigabytes limit. This is referred to as extended memory and you can learn more about this in the link section of this video, the first thing you want to consider when choosing a region and zone is the geographical location in which you want to run your resources. This map shows the current and plant GDP regions and the number of zones. For up to date information on the available regions and zones. See the documentation linked for this video. Each zone supports a combination of ivy bridge, Sandy Bridge hassle brought wall and skylight platforms. When you create an instance in the zone, your instance will use the default processes supported in that zone. For example, if you create an instance in the U. S. Central one, a zone your instance will use the Sandy Bridge processor.
Compute pricing

[Autogenerated] G. C. P. Offers a variety of different options to keep the prices low For compute engine, resources all the Cpus, Gpus and gigabyte of memory are charged a minimum of one minute. For example if you run your virtual machine for 30 seconds you will build for one minute of usage after one minute instances are charged in one second. Increments, compute engine uses a resource based pricing model where each virtual CPU and each gigabyte of memory and compute engine is built separately rather than this part of a single machine type, you still create instances using predefined machine types but you build reports them as individual V. Cpus and memory used. There are several discounts available but the discount types cannot be combined. There are research based pricing which allows computer engine to apply sustained use discounts to all of your predefined machine types usage in a region collectively rather than to individual machine types. If your workload is stable and predictable, you can purchase a specific amount of the CPU and memory for a discount off of normal prices in return for committing to a usage term of one or three years, the discount is up to 57% for most machine types or custom machine types. The discount is up to 70% for memory. Optimized machine types. A preemptive of'em is an instance that you can create and run at much lower price than normal instances. However, compute engine might terminate or preempt these instances if it requires access to those resources for other tasks. Preempt herbal instances, our access compute engine capacity. So the availability varies with usage. The ability to customize the amount of memory and CPU through custom machine types allows her further pricing customization. Speaking of sizing your machine, compute engine provides VM. Sizing recommendations to help you optimize the resource use of your virtual machine instances. When you create a new instance, recommendations for the new instance will appear 24 hours after the instance has been created, compute Engine also has free usage limits. For the exact terms. Please refer to the link section of this video sustained use discounts are automatic discounts that you get for running specific compute engine, resources BCPs, memory and GPU devices for a significant portion of the billing month. For example, when you run one of these resources for more than 25% of a month, computer engine automatically gives you a discount for every incremental minute you use for that instance, the discount increases with usage and you can get up to 30% net discount for instances that run the entire month. This table shown on this slide describes the discount you get at each usage level off a VM instance. To take advantage of the full 30% discount, create your VM instances on the first day of the month. Because this country set at the beginning of each month. The graph on the slide demonstrates how your effective discount increases with use. For example if you use a virtual machine for 50% of the month, you get an effective discount of 10%. If you use it for 75% of the month you get an effective discount of 20% and if you use it for 100% of the month you get an effective discount of 30%. You can also use the G. C. P. Pricing calculator to estimate your sustained use discounts for any arbitrary workload for the calculator. See the link section of this video computer engine, calculates sustained use discounts based on V. CPU and memory usage across each region and separately for each of the fallen categories. Predefined machine types and custom machine types. Let's go through an example where you have two instances that are in the same region but have different machine types and run at different times of the month. Compute engine, breaks down the number of the Cpus and amount of memory used across all instances that use predefined machine types and combines the resources to qualify for the largest sustained usage discounts possible. As shown on this slide, you run the following two instances in the U. S. Central one region. During a month. For the first half of the month you run an anyone standard for instance with four virtual Cpus and 15 gigabytes of memory for the second half of the month you run a larger and one standard 16 instance with 16 virtual Cpus and 60 gigabytes of memory. In this scenario, computer engine reorganizes these machine types into individual V. Cpus and memory resources and combines the usage to create the following resources as shown on the bottom four virtual Cpus and 15 gigabytes of memory for a full month, and then 12 virtual Cpus and 45 gigabytes of memory for half of the month.
Special compute configurations

[Autogenerated] as I mentioned earlier, a pre empt able VM is an instance that you can create and run at much lower prices than normal instances. See whether you can make your application functional completely unpredictable VMS because an 80% discount is a significant investment in your application now. Just to reiterate these VMS might be preempted at any time and there is no charge if that happens within the 1st 10 minutes. Also preemptively VMS are only going to live for up to 24 hours and you only get authority second notification before the machine is preempted. It's also worth noting that there are no live migrations nora automatic restarts in pre empt Herbal VMS but something that we will highlight is that you can actually create monitoring and load balances, then can start up new preemptive of VMS in case of failure. In other words, there are external ways to keep restarting preemptive VMS if you need to, one major use case of preemptive of VMS is running a batch processing job. If some of those instances terminate during processing, the job slows down but does not completely stop. Therefore, preempt herbal instances complete your batch processing tasks without placing additional workload on your existing instances and without requiring you to pay full price for additional normal instances. If you have workloads that require physical isolation from other workloads or virtual machines in order to meet compliance requirements, you want to consider Soul Talent Notes. A sole tenant. Note is a physical computer engine server that is dedicated to hosting VM instances only for your specific project. You sold Tennant Notes to keep your instances physically separated from instances in other projects or to group your instances together on the same host hardware. For example, if you have a payment processing workload that needs to be isolated to meet compliance requirements. The diagram on the left shows a normal host with multiple VM instances from multiple customers. A sole tenant node, as shown on the right, also has multiple VM instances, but they all belong to the same project as of this recording. The only available no type can accommodate VM instances up to 96 V c p u s and 624 gigabytes of memory. You can also fill the note with multiple smaller VM instances of various sizes, including custom machine types and instances with extended memory. Also, if you have existing operating system licenses, you can bring them to compute engine using sole tenant notes while minimizing physical core usage with the in place restart feature to learn how to create notes and place your instances on those notes. See the link section of this video. Another computer option is to create shielded VMS shielded VMS offer verifiable integrity of your VM instances so you can be confident that your instances haven't been compromised by boot or kernel level malware or root kits. Shielded VMS, verifiable integrity is achieved through the use of secure boot, virtual trusted platform module or V TPM enabled, measured boot and integrity monitoring. Shielded VMS is the first offering in the shielded caught initiative. The Sheila card initiative is meant to provide an even more secure foundation for all of G C P by providing verifiable integrity and offering features like the TPM shielding or ceiling that help prevent data exfiltration. In order to use these shielded VM features, you need to select a shielded image. We learn about images in the next section.
Images

[Autogenerated] Next let's focus on images when creating a virtual machine, you can choose the boot disk image. This image includes the bootloader, the operating system, the file system structure, any pre configured software and any other customers ations. You can select either a public or custom image as you saw in the previous lab. You can choose from both. Linux and Windows Images. Some of these images are premium images as indicated in parentheses. Would API These images will have per second charges after a one minute minimum. With the exception of sequel server images, which are charged permanent after a 10 minute minimum. Premium images vary with the machine type. However, these prices are global and do not vary by region or zone. You can also use custom images. For example, you can create and use a custom image by pre installing software that's been authorized for your particular organization. You also have the option of importing images from your own premises or workstation or from another cloud provider. This is a no cost service that is as simple as installing an agent and I highly recommend that you look at it. You can also use custom images. For example, you can create and use a custom image by pre installing software that's been authorized for your particular organization. A machine image is a compute engine resource that stores all the configuration, metadata, permissions and data from one or more disks required to create a virtual machine instance, you can use a machine image in many system maintenance scenarios such as creation backup recovery and instance, clowning machine images are the most ideal resources for disk backups as well as instance. Cloning and replication. Please note at time of writing machine images were still in beta.
Disk options

[Autogenerated] at this point, you've chosen an operating system, but that operating system is going to be included as part of some kind of disc. So let's look at the disk options. Every single VM comes with a single root persistent disk because you're choosing a base image to have it loaded on this image is bookable in that it can attached to a VM and boot from it and it is durable in that it can survive of the VM terminates to have a boot disk, survivor VM deletion. You need to disable the delete boot disk when instances deleted option in the instance properties as we discussed earlier, there are different types of disks. So let's explore these in more detail. The first disc that we created is what we call a persistent disk. That means that it's going to be attached to the VM through the network interface, even though it's persistent, it's not physically attached to the machine. This separation of disk and compute allows the disk to survive. If the VM terminates, you can also perform snapshots of these discs which are incremental backups that we'll discuss later on. The choice between HDD and SSD disks comes down to cost and performance to learn more about disk performance and how it scales with disk size. See the link section of this video. Another cool feature of persistent disks is that you can dynamically resize them even when they're running and attached to VM, you can also attach a disk in a read only mode to multiple VMS. This allows you to share static data between multiple instances, which is cheaper than replicating your data to unique discs for individual instances. Zonal persistent disks offer efficient, reliable block storage. Regional persistent disks provide active active disk replication across two zones. In the same region, regional persistent disks provide durable storage that is synchronously replicated across zones. And our great option for high performance databases and enterprise applications that also require high availability. When you configure a zonal or regional persistent disk, you can select one of the following disc types. Standard persistent disks, these discs are backed by a standard hard disk drive, balanced persistent disks. These types of discs are backed by solid state drives. They are an alternative to SSD persistent disks that balanced performance and cost as a steep persistent disks. These types of discs are backed by solid state drives by default compute engine, encrypts all data at rest, google cloud handles and manages this encryption for you without any additional actions on your part. However, if you wanted to control and manage this encryption yourself, you can use either cloud key management service to create and manage key encryption keys or create and manage your own key encryption keys. Now, local SSD s are different from persistent disks in that they are physically attached to the virtual machine. Therefore, these discs are ephemeral but they provide very high IOPS for up to date numbers. I recommend referring to the documentation. Currently you can attach up to eight local SSD disks with 375 gigabytes each, resulting in a total of three terabytes. Data on these discs will survive a reset but not a VM, stop or terminate because these disks cannot be reattached to a different VM. You also have the option of using RAM disks. You can simply use TMP Fs if you want to store data in memory, this will be the fastest type of performance available if you need small data structures. I recommend a high memory virtual machine if you need to take advantage of such features along with a persistent disk to back up the RAM data. In summary, you have several different disk options. Persistent disks can be rebooted and snapshot it, but Local SST S and RAM disks are ephemeral. I recommend choosing a persistent HDD disk if you don't need the performance, but just the capacity if you have high performance needs, start looking at SSD options, persistent disks offer data redundancy because the data on each persistent disk is distributed across several physical disks. Local SSD s provide even higher performance but without data redundancy. Finally, RAM disks are very volatile but they provide the highest performance. No, just as there's a limit to how many local SSD s you can attach to a VM. There is also a limit on how many persistent disks you can attach to A via. As illustrated in this table. This limit depends on the machine type. For shared core machine type, you can attach up to 16 discs for the standard. High memory, high CPU memory optimized and compute optimized machine types. You can attach up to 128 disks so you can create massive mental capacity for a single host. Now, remember that little nuance. When I told you about how throughput is limited by the number, of course that you have that True. Put also shares the same bandwidth as disk I. O. So if you're planning on having a large amount of disk I. O. Throughput, it will also compete with any network egress or ingress through Bush. So remember that especially if you'll be increasing the number of drives attached to a virtual machine. There are many differences between a physical hard disk in a computer and a persistent disk, which is essentially a virtual network device. First of all, if you remember with normal computer hardware disks, you have to partition them essentially you have a drive and you're carving up a section for the operating system to get its own capacity. If you want to grow it, you have to re partition and if you want to make changes, you might even have to reformat if you want redundancy, you might have to create a redundant disk array. And if you want encryption, you need to encrypt the files before writing them to a disk with cloud persistent disks, things are very different because all that management is handled for you on the back end. You can simply grow disks and resize the file system because disks are virtual network devices redundancy and snapshot services are built in and disks are automatically encrypted. You can even use your own keys and that will ensure that no party can get to the data except you.
Common Compute Engine actions

[Autogenerated] now that we have covered all the different compute image and disk options. Let's look at some common actions that you can perform with compute engine. Every VM instance stores its metadata on a metadata server. The metadata server is particularly useful in combination with startup and shutdown scripts because you can use the metadata server to programmatically get unique information about an instance without additional authorization. For example, you can write a startup script that gets the metadata key value pair for an instance is external I. P. Address and use that I. P. Address in your script to set up a database. Because the default metadata keys are the same on every instance, you can reuse your script without having to update it for each instance. This helps you create less brittle code for your applications, storing and retrieving instance, metadata is a very common compute engine action. I recommend storing the startup and shutdown scripts in cold storage as you will explore in the upcoming lab of this module. Another common action is to move an instance to a new zone. For example, you might do so for geographical reasons or because the zone is being deprecate id. If you move your instance within the same region, you can automate the move by using the G cloud, compute instances, move command. If we move your innocence to a different region, you need to manually do so by following the process outlined here. This involves making a snapshot of all persistent disks and creating new disks in the destination zone. From that snapshot next you create the new VM. Indeed destination zone and attached the new persistent disks, assign a static iP and update any references to the VM. Finally, you delete the original VM. It's disks and the snapshot. Speaking of snapshots, let's take a closer look at these snapshots have many use cases, for example, they can be used to back up critical data into a durable storage solution to meet application availability and recovery requirements. These snapshots are stored in cloud storage which is covered. Later snapshots can also be used to migrate data between zones. I just discussed this when going over the manual process of moving an instance between two regions, but this can also be used to simply transfer data from one zone to another. For example, you might want to minimize latency by migrating data to drive that can be locally attached in the zone where it is used, which brings me to another snapshot use case transferring data to a different disk type. For example, if you want to improve disk performance, you could use a snapshot to transfer data from a standard HD persistent disk to a SSD persistent disk. Now that I've covered some of these snapshot use cases, let's explore the concept of a disk snapshot. First of all, this slide is titled persistent disk snapshots because snapshots are available only to persistent disks and not to local. SSD s snapshots are different from public images and custom images which are used primarily to create instances or configure instance templates in that snapshots are useful for periodic backup of the data on your persistent disks, snapshots are incremental and automatically compressed so you can create regular snapshots on a persistent disk faster and at a much lower cost than if you regularly created a full image of the disk as we saw with the previous examples, snapshots can be restored to a new persistent disk, allowing for a move to a new zone to create a persistent disk snapshot. See the links section of this video. Another common compute engine action is to resize your persistent disk. The added benefit of increasing storage capacity is to improve I. O performance. This can be achieved while the disk is attached to a running VM, without having to create a snapshot now, while you can grow distance size, you can never shrink them. So keep this in mind.
Lab Intro: Working with Virtual Machines

[Autogenerated] Let's get started with the second lab of this module. In this lab, you'll be setting up an application server. Now this example happens to be a gaming application, but it applies to many other use cases. You will configure the VM and also add capacity for a production gaming system and you will build the infrastructure that you need for production activities. These include backups and graceful shutdown and restart services
Lab: Working with Virtual Machines

Lab Review: Working with Virtual Machines

[Autogenerated] in this lab, you created a customized virtual machine instance by installing based software which was a headless, java runtime environment and application software. Specifically a Minecraft game server. You customize the VM by preparing and attaching a high speed SSD and you've reserved a static external iP address, said that the address would remain consistent using that iP address. You then verify the availability of the gaming server online. Next you set up a backup system to back up the service data to a cloud storage bucket and then you tested that backup system. You then automated backups using Chrome Finally, you set up maintenance scripts using metadata for graceful startup and shutdown of the server. Many of these techniques, including the script automation can be adapted to administration of production service in any application you can stay for lab walkthrough. But remember that GPS user interface can change so your environment might look slightly different. So here I am in the VM instances page, let's go ahead and create our instance. We're going to use the same properties that are provided to US properties and values in the lab. So I'm going to call it the server for Minecraft Server, we're going places in the U S central one a zone. We're going to modify the axis scopes for this. So I'm going to set access for each API and I'm going to modify for storage that besides just read only. I want to read. Right. This is going to allow the VM instance to ride to a cloud storage bucket that we're going to create later on now. We're also going to modify the disk of this instance. So let's expand the option down here and under disks, we're going to add a new disk and we're going to call this the Minecraft disk and we are going to make that an SSD persistent disk, it's going to have, it's going to be blanks or no source. Um 50 gigabytes is more than enough what we're trying to do and I'm going to leave the encryption as google managed key so let me click done. And this is going to create that disk on automatic, attach it to the VM. Now under networking we're also going to add a network tag and this is going to then allow us to create specific firewall rules. Call that Minecraft server on the network interface. I'm going to click on the pencil icon here to edit um We are leaving the internal iP's but for the external iP we're actually going to create an IP address which means that we are reserving a static iP address and this is going to make sure that these I. P address is not ephemeral and doesn't change. So just give it a name and I click reserve and then we're going to like done once that is reserved from there. We're going to create this instance done and then create now once the instance is up and running we're going to have to prepare the data disks. So we're not going to create a directory format and mount the disk. I don't need this type over here so I can close that. We're gonna wait for the instance there it is. So let me SSH to the instance and I'm going to start by creating a director that serves as the amount point for the data after disk. And for that I'm just going to use the command that's provided in the lab and then we're going to format that this gets off so we're just going to wait for that ssh connection to be established. This is allowed because the default network has a default firewall rule for us, it's age. So let me go ahead and run that. And then we are going to format the disk. Okay. And now we're going to mount it and this is not going to display any output. So don't be surprised about that. Um there's a checkpoint in the lab so you can check your progress worked for me. I'm going to move on to task three and now install and run the application and the micro server itself runs on top of the java virtual machine. So we do require the java runtime environment or _____ to run but we don't need the user interface. So we're just going to install actually headless version and that's going to reduce a lot of the resource usage on that machine, which will ensure that the micro server has enough room to expand its own resource usage if needed. So let me go ahead and start by updating the repository and then I'm going to install that headless _____ and after that I'm going now navigate to the directory where we mounted that persistent disk and into that we're then going to download the Minecraft jar file. We'll never get into that. And the command you can see it's downloading and the lab manual also provides information on the download page itself so you can read more about where this comes from. There. Also lots of instructions actually in there on how to set this up on a Windows machine. So if you wanted to customize this, I definitely recommend referring to that link. So let's go ahead and initialize the Minecraft server running the command and it's telling us that this is not going to run unless we agree to the end user licensing agreement. So we need to do that now. Let me just check my progress, make sure that the _____ installation and Microsoft installation worked out. And I got a green check in my lab. So let's look at the files that were created to identify where this license agreement is and there it is. We can see it right there. So let me use nano to edit that now. And all we really have to do is we have to change his last line instead of saying false. We just have to agree to it by setting this to truth. So let me change that. And then we're going to like control oh to write that to that file name, hit, enter and then control X to come back out. Okay, so we're not going to try to restart the Minecraft survey yet. We're going to use a different technique in a second. What we're going to do next is we're going to create a virtual terminal screen to start. That's a verb. And to do that, we're going to install screen. So let's grab that command from the lab instructions. Okay. It seems like it was already actually installed and then we're gonna go ahead and start that now using the screen command. So let's run that and this might take a while now, but it's going to establish the whole environment for us so we can see here it's preparing the level world. It's loading some recipes. So these are all now very specific commands in regarding in regards to the gaming application that we're installing here. We're going to wait for this to complete before detaching from this and moving on so we can see that the spawn area here has been completed. We could now detach from this. But one thing I want to point out that we're going to do have to do next is when this whole thing started, it told us which port it is going to do that for. So the port is right here and we're going to have to create a firewall rule in a second to actually allow client traffic to that port so we can now detach from this. So we're going to just use control and control. D to get out of here. There is a command if you wanted to re attach to that terminal, we're not going to do that. So I'm just going to exit out of here and we're now going to allow client traffic. So for that we need to create a firewall rule and we're going to use the network tack that we created, which we can display by going to columns and then network tags. We can see that Minecraft server was the network tag. So let's do that. I'm going to navigate to VPC network and specifically firewall rules. I'm going to give a new firewall rule the name of Minecraft rule. Okay. And it's going to be on the default network with just the only that we have right now. And for specify target tags, we're now going to define Minecraft servers will only apply to the instances that have that tag. So let me define um the IP ranges as from anywhere and now specifically for the protocol that's TCP and then that port was too 5565 And then I'm going to go ahead and click create and once it's up and running we're going to verify the availability of the server so I can already start navigating back and I'll monitor the process at the end of notification pane. I'm going back to compute engine and we have the external IP address here and we're now going to use a couple different ways to verify that this is running note that we can't click on it because we didn't enable HTTP that would have been TCP for port 80 in the lab instructions. We have listed a website and we also currently have a chrome extension there have that chrome extension actually right up here. So let's try that. I'm going to go to options, change the iP address that is in here, save that and then we're going to try to verify and I can change this to my Minecraft server. Save those changes and then we're going to keep an eye on here to see if this is coming up alternative. Also, we could use any of the websites that are listed in here um, since these are third party tools, sometimes they don't work. So that's definitely something to keep in mind. And I think that's actually what's going on right now with this extension. It doesn't seem to want to display this to us right now. Um, but if I check the box in the lab instructions itself, it's telling me that everything is tracked correctly. So we've done all the work. It's just that sometimes again, these third party tools that we're using to test the status may not always work. There is another one that I can try really fast and we could grab the external p address and copied in there and get the server status that way. And it is telling us that it does have it. Um, so it it is up and running currently has no players in it and it tells us the exact version that we're running. So clearly it is working for this page, just not for the chrome extension right now. All right. So then let's move on. What we're going to do now is these services up and running, but now we want to actually schedule some regular backups, have some maintenance around the server so that we kind of plan for the long term. So what I can do now is I can ssh back into the server and since I allowed for read, write access to cloud storage, I can actually directly create a bucket now through my server here similarly as you would from CloudTrail So the first thing I'm gonna do is I'm just going to define my own bucket name and stored in an environment variable. So here we go, export your bucket name and you want to use something that's globally unique. So, one thing we could do is we could take our project idea, take that right here and we go back to that server and ____ it in there. Alright. Whenever you created an environment variable, you want to run the echo command to make sure that you created it correctly here. We can see that worked. And now I can use the gee sutil command specifically M B for make bucket for google cloud storage and then I use that unique part that I just entered and just append Minecraft back up so that I also kind of know what this is. So this becomes a little more readable. Great. So there it is. I could also now verify by the way that it is created in my project, I could go to the navigation menu and if we go to storage we'll be able to see our pocket right here. We could have also just created it this way, but this way we now have everything stored that is the variable in here and then going forward we can do all of the backup right through the VM. So let's go ahead and create a backup script. I'm just going to navigate to the home directory that we have within Minecraft and we're going to just create a new script using nano and I'm going to paste the script that we already have in here, which has a screen command and then talks about the backup. So let me pieces in there and then we're going to press control Oh and then enter to save and control likes to come back. So the script saves the current state of the servers world and pauses the service odyssey functionality. And then it's going to back up the service World Data Directory and places its content in a timestamp directory in the cloud storage market. And then after the script finished this back up the data, it resumes auto saving on the Minecraft server. Now we've got to make sure that this is actually executable So let's run the following command and now we can go and test us. So let's actually run the backup script. Okay, so that we can see that we are copying some files and let's verify that. So I'm going to now navigate into my cloud storage bucket that I already have here. If I open that we can now see a folder in there and I could dig further into their to get more information about the world. So clearly we can see that the backup is working for us. Now we can also now schedule the backup to run in a more automated fashion. So I'm going to go back to my ssh session, run the Sudoku on top command. Now we want to choose nano in this case does tell us it's easiest, but you do have other options available if those are more comfortable. And at the bottom we're now going to define how often this runs and this is going to tell it to run the backup every four hours. There's documentation that you can look into and how to define this. But in this case that's more than enough for what we're trying to achieve. So let's save that file and get back out and this is going to create a lot of backups about 300 a month. So maybe you want to look into regularly deleting those. Cloud storage does offer object lifecycle management features that let you set time to live for objects and even archive older objects to a different storage class. And you'll learn more about that in the next course of this series. When we talk about cloud storage, I'm just going to go ahead and check my progress in my lab looks like everything worked. And the last thing we're gonna do is now perform some maintenance. So specifically when we shut down and restart that certain actions happen. So let me run the pseudo screen command and then I'm going to go and actually stop this instance. So I'm going to go navigate to compute engine, click on D server, so select it and click stop. It's gonna ask us if we sure we want to do that and yes, we're going to stop and then later if we wanna start to pick up, we can do that. This is also going to lock us out of our ssh session obviously. So let's wait for this to stop. And then we're going to um automate the server maintenance with some startup and shutdown scripts. So the instance has stopped, I'm going to click on it now to edit some of the custom metadata. So let me click edit and we're going to scroll down to the metadata. Here we go. And what we're going to define out is a startup script as well as a shutdown script. And we're going to point those two files that we have in college storage that are public available. So the key is going to be startup script, URL and then the value is going to be the location of the file and I can make that bigger to make sure that formatting that correctly. I'll add another item. We do the same for the shutdown script and you can actually navigate yourself to these files if you want to and you can read more about what exactly happens in the startup and shutdown scripts so now I can click save and I could restart the service. Um I did in the meantime, while the service was shutting down, I went back to the status page and you can see that the status is currently says could not resolve so clearly the server is shut down and now when we restart this, once all the startup script is done running, we can go back and we can verify that this service is indeed now accessible again. Um Just keep in mind that that might take a while for the actual instance to start up, which is now and then for the startup script to actually finish.
Module Review

[Autogenerated] In this module, we covered the different compute image and disk options within compute engine, along with some common actions, the two labs provided you with real world applications of most of the topics covered in this course, remember there are many computer options to choose from. If a predefined machine type does not meet your needs. You can also customize your own VM and you can even create a sole tenant note. You can also install different public and custom images on the boot disks of your instances, and you can attach more disks if need it.
Course Review

[Autogenerated] Thank you for taking the Essential Cloud Infrastructure Foundation course. I hope you have a better understanding of how to architect with compute engine and I also hope that the demos and labs made you feel more comfortable with using the different G C. P services that we covered next. I recommend enrolling in the Essential Cloud Infrastructure core services course of the Architect in with google compute engine series. In that course we start by talking about cloud I am and you will administer identity and access management for resources. Next we'll cover the different data storage services in G C P and you will implement some of those services. Then we'll go into a resource management where you will manage and examine billing data of DcP resources Lastly, we'll talk about resource monitoring and you will monitor G C p. resources using stack drivers. services enjoy that course.
Next Course: Essential Cloud Infrastructure: Core Services

Course Resources